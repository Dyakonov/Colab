{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "322d2e71-5af6-483f-9044-03d91532c7b8",
      "metadata": {
        "id": "322d2e71-5af6-483f-9044-03d91532c7b8"
      },
      "source": [
        "# Добавки\n",
        "\n",
        "#### Что отдельно пройти\n",
        "\n",
        "* TensorBoard https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
        "* https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html\n",
        "* torchvision\n",
        "* torchaudio\n",
        "* torchtext\n",
        "* Debug\n",
        " * anomaly detection: torch.autograd.detect_anomaly or torch.autograd.set_detect_anomaly(True)\n",
        " * profiler related: torch.autograd.profiler.emit_nvtx, torch.autograd.profiler.profile\n",
        " * autograd gradcheck: torch.autograd.gradcheck or torch.autograd.gradgradcheck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f2e7db1-1340-4dc0-8024-cfec0a3c3849",
      "metadata": {
        "id": "1f2e7db1-1340-4dc0-8024-cfec0a3c3849"
      },
      "outputs": [],
      "source": [
        "# from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# что разумно сразу импортировать\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Einsum"
      ],
      "metadata": {
        "id": "HjYmkgXT77Bq"
      },
      "id": "HjYmkgXT77Bq"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "X = torch.tensor([[11, 12, 13], [21, 22, 23], [31, 32, 33]])\n",
        "Y = torch.tensor([[1, 1, 1], [0, 2, 1], [0, 0, 3]])\n",
        "print (X)\n",
        "\n",
        "print (torch.einsum('ij, ij -> ij', X, Y)) # умножение матриц\n",
        "\n",
        "print (torch.einsum('ii -> i', X)) # диагональ\n",
        "\n",
        "print (torch.einsum('ij, ij -> ij', X, Y)) # адамарово умножение\n",
        "\n",
        "print (torch.einsum('ii -> ', X)) # след\n",
        "\n",
        "print (torch.einsum('ij -> ji', X)) # транспонирование\n",
        "\n",
        "print (torch.einsum('ij -> j', X)) # сумма по оси\n",
        "\n",
        "print (torch.einsum('ij -> ', X)) # сумма всех элементов\n",
        "\n",
        "# import einops\n",
        "# einops.repeat(x, 'm n -> m k n', k=K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80EcJvis76Sw",
        "outputId": "12bad460-0afa-4a4d-9a60-9b44ce6cdf23"
      },
      "id": "80EcJvis76Sw",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11, 12, 13],\n",
            "        [21, 22, 23],\n",
            "        [31, 32, 33]])\n",
            "tensor([[11, 12, 13],\n",
            "        [ 0, 44, 23],\n",
            "        [ 0,  0, 99]])\n",
            "tensor([11, 22, 33])\n",
            "tensor([[11, 12, 13],\n",
            "        [ 0, 44, 23],\n",
            "        [ 0,  0, 99]])\n",
            "tensor(66)\n",
            "tensor([[11, 21, 31],\n",
            "        [12, 22, 32],\n",
            "        [13, 23, 33]])\n",
            "tensor([63, 66, 69])\n",
            "tensor(198)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407e27c0-9092-4393-b589-cf61130a84f5",
      "metadata": {
        "id": "407e27c0-9092-4393-b589-cf61130a84f5"
      },
      "source": [
        "# AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "470e5d89-87ce-42ef-9081-6da63d37fbea",
      "metadata": {
        "id": "470e5d89-87ce-42ef-9081-6da63d37fbea",
        "outputId": "3315ab6b-7423-4223-84b3-b0089724925d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-2e27e419d160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAlexNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         self.features = nn.Sequential(\n",
            "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11,\n",
        "                      stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5,\n",
        "                      padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3,\n",
        "                      padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3,\n",
        "                      padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3,\n",
        "                      padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001bd121-d4d7-4b41-8cbf-77051ed5b6fb",
      "metadata": {
        "id": "001bd121-d4d7-4b41-8cbf-77051ed5b6fb"
      },
      "outputs": [],
      "source": [
        "# ??\n",
        "\n",
        "\n",
        "\n",
        "from torch.hub import load_state_dict_from_url\n",
        "model_urls = {\n",
        "    'alexnet':\n",
        "    'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "def alexnet(pretrained=False,\n",
        "            progress=True, **kwargs):\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(\n",
        "              model_urls['alexnet'],\n",
        "              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47105a14-c6d5-49b6-b6bd-4b32331487c4",
      "metadata": {
        "id": "47105a14-c6d5-49b6-b6bd-4b32331487c4"
      },
      "source": [
        "## LR find\n",
        "\n",
        "fast.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773981c1-b796-4a51-8d47-d3ef98fb8676",
      "metadata": {
        "id": "773981c1-b796-4a51-8d47-d3ef98fb8676"
      },
      "outputs": [],
      "source": [
        "def find_lr(model, loss_fn, optimizer, train_loader, init_value=1e-8, final_value=10.0, device=\"cpu\"):\n",
        "    number_in_epoch = len(train_loader) - 1\n",
        "    update_step = (final_value / init_value) ** (1 / number_in_epoch)\n",
        "    lr = init_value\n",
        "    optimizer.param_groups[0][\"lr\"] = lr\n",
        "    best_loss = 0.0\n",
        "    batch_num = 0\n",
        "    losses = []\n",
        "    log_lrs = []\n",
        "    for data in train_loader:\n",
        "        batch_num += 1\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # Crash out if loss explodes\n",
        "\n",
        "        if batch_num > 1 and loss > 4 * best_loss:\n",
        "            if(len(log_lrs) > 20):\n",
        "                return log_lrs[10:-5], losses[10:-5]\n",
        "            else:\n",
        "                return log_lrs, losses\n",
        "\n",
        "        # Record the best loss\n",
        "\n",
        "        if loss < best_loss or batch_num == 1:\n",
        "            best_loss = loss\n",
        "\n",
        "        # Store the values\n",
        "        losses.append(loss.item())\n",
        "        log_lrs.append((lr))\n",
        "\n",
        "        # Do the backward pass and optimize\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the lr for the next step and store\n",
        "\n",
        "        lr *= update_step\n",
        "        optimizer.param_groups[0][\"lr\"] = lr\n",
        "    if(len(log_lrs) > 20):\n",
        "        return log_lrs[10:-5], losses[10:-5]\n",
        "    else:\n",
        "        return log_lrs, losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c68f89-7840-4051-a97c-7d7ac11f7d03",
      "metadata": {
        "id": "43c68f89-7840-4051-a97c-7d7ac11f7d03"
      },
      "source": [
        "## Ансамблирование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9849575d-ef20-4ddd-bbf7-fda9d938d7c2",
      "metadata": {
        "id": "9849575d-ef20-4ddd-bbf7-fda9d938d7c2"
      },
      "outputs": [],
      "source": [
        "models_ensemble = [models.resnet50().to(device), models.resnet50().to(device)]\n",
        "predictions = [F.softmax(m(torch.rand(1,3,224,244).to(device))) for m in models_ensemble]\n",
        "avg_prediction = torch.stack(predictions).mean(0).argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31fff36-bcd6-4639-8080-99e770ddb5c8",
      "metadata": {
        "id": "e31fff36-bcd6-4639-8080-99e770ddb5c8"
      },
      "source": [
        "# Иллюстрация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d68b69e8-52f2-4366-9414-2900de52a9cb",
      "metadata": {
        "id": "d68b69e8-52f2-4366-9414-2900de52a9cb"
      },
      "outputs": [],
      "source": [
        "# Dummy values to get code to run in the next cells\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "n_epochs = 1\n",
        "model = nn.Linear(10,10)\n",
        "dataset = [(torch.rand(10),torch.rand(10))]*20\n",
        "train_dataloader = DataLoader(dataset)\n",
        "\n",
        "val_dataloader = DataLoader(dataset)\n",
        "test_dataloader = DataLoader(dataset)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28dd6241-8f8c-4c2d-b70c-83738d41e50f",
      "metadata": {
        "id": "28dd6241-8f8c-4c2d-b70c-83738d41e50f"
      },
      "outputs": [],
      "source": [
        "for epoch in range(n_epochs):\n",
        "\n",
        "    # Training\n",
        "    for data in train_dataloader:\n",
        "        input, targets = data\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input)\n",
        "        train_loss = criterion(output, targets)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        for input, targets in val_dataloader:\n",
        "            output = model(input)\n",
        "            val_loss = criterion(output, targets)\n",
        "\n",
        "# Test\n",
        "with torch.no_grad():\n",
        "    for input, targets in test_dataloader:\n",
        "        output = model(input)\n",
        "        test_loss = criterion(output, targets)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28cd3f12-206c-4e83-b32a-e90d86f13e79",
      "metadata": {
        "id": "28cd3f12-206c-4e83-b32a-e90d86f13e79"
      },
      "outputs": [],
      "source": [
        "for epoch in range(n_epochs):\n",
        "    total_train_loss = 0.0 # <1>\n",
        "    total_val_loss = 0.0  # <1>\n",
        "\n",
        "    if (epoch == epoch//2):\n",
        "      optimizer = optim.SGD(model.parameters(),\n",
        "                            lr=0.001) # <3>\n",
        "    # Training\n",
        "    model.train() # <2>\n",
        "    for data in train_dataloader:\n",
        "        input, targets = data\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input)\n",
        "        train_loss = criterion(output, targets)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += train_loss # <1>\n",
        "\n",
        "    # Validation\n",
        "    model.eval() # <2>\n",
        "    with torch.no_grad():\n",
        "      for input, targets in val_dataloader:\n",
        "          output = model(input)\n",
        "          val_loss = criterion(output, targets)\n",
        "          total_val_loss += val_loss # <1>\n",
        "\n",
        "    print(\"\"\"Epoch: {}\n",
        "          Train Loss: {}\n",
        "          Val Loss {}\"\"\".format(\n",
        "         epoch, total_train_loss,\n",
        "         total_val_loss)) # <1>\n",
        "\n",
        "# Test\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for input, targets in test_dataloader:\n",
        "      output = model(input)\n",
        "      test_loss = criterion(output, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34ff219c-2cc5-4066-9af8-4594ef89091f",
      "metadata": {
        "id": "34ff219c-2cc5-4066-9af8-4594ef89091f"
      },
      "source": [
        "# TPU\n",
        "\n",
        "обучение на TPU напрямую не поддерживается в pytorch, надо использовать PyTorch/XLA (Accelerated Linear Algebra)\n",
        "\n",
        "см. https://github.com/pytorch/xla/\n",
        "\n",
        "Как можно запустить в колабе:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07205f5-81d5-47bc-8bcf-e0e9180edc46",
      "metadata": {
        "id": "b07205f5-81d5-47bc-8bcf-e0e9180edc46"
      },
      "outputs": [],
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version \"nightly\"\n",
        "\n",
        "import torch_xla.core.xla_model as xm\n",
        "device = xm.xla_device()\n",
        "\n",
        "# Dummy values to get code to run in the next cells\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "n_epochs = 1\n",
        "model = nn.Linear(10,10)\n",
        "dataset = [(torch.rand(10,requires_grad=True),torch.rand(10,requires_grad=True))]*20\n",
        "\n",
        "trainloader = DataLoader(dataset)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.001)\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "for epoch in range(n_epochs):\n",
        "    for data in trainloader:\n",
        "        input, labels = data\n",
        "        input = input.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(input)\n",
        "        loss = criterion(input, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(output.device) # out: xla:1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae69032-5383-4380-9235-a959cc83fe8a",
      "metadata": {
        "id": "bae69032-5383-4380-9235-a959cc83fe8a"
      },
      "source": [
        "# Multiple GPUs (Single Machine)\n",
        "\n",
        "Есть несколько видов распараллеливания:\n",
        "\n",
        "- data parallel processing\n",
        "- model parallel processing (не будем описывать)\n",
        "\n",
        "(но это не проверить в колабе)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee89a348-f426-4b65-b0ee-11d73d706ed5",
      "metadata": {
        "id": "ee89a348-f426-4b65-b0ee-11d73d706ed5"
      },
      "outputs": [],
      "source": [
        "# data parallel processing (1й способ)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"This machine has\", torch.cuda.device_count(),  \"GPUs available.\")\n",
        "    model = nn.DataParallel(model) # перед отправкой на device\n",
        "model.to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "782e4138-853b-4ea7-93b1-9beff18c870b",
      "metadata": {
        "id": "782e4138-853b-4ea7-93b1-9beff18c870b"
      },
      "outputs": [],
      "source": [
        "# data parallel processing (2й способ - предпочтительный)\n",
        "\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.parallel import DistributedDataParallel as DD\n",
        "\n",
        "def dist_training_loop(rank, world_size, dataloader, model, loss_fn, optimizer):\n",
        "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
        "    model = model.to(rank)\n",
        "    ddp_model = DDP(model, device_ids=[rank])\n",
        "    optimizer = optimizer(ddp_model.parameters(), lr=0.001)\n",
        "    for epochs in range(n_epochs):\n",
        "        for input, labels in dataloader:\n",
        "            input = input.to(rank)\n",
        "            labels = labels.to(rank)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = ddp_model(input)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    world_size = 2\n",
        "    mp.spawn(dist_training_loop, args=(world_size,), nprocs=world_size, join=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea07b76a-9aaf-477c-86d9-ca1cd26113bb",
      "metadata": {
        "id": "ea07b76a-9aaf-477c-86d9-ca1cd26113bb"
      },
      "source": [
        "# Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb36211a-c07e-4fdd-8aef-fcd38b6d58b0",
      "metadata": {
        "id": "fb36211a-c07e-4fdd-8aef-fcd38b6d58b0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(\n",
        "            F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(\n",
        "            F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1,\n",
        "                   int(x.nelement() / x.shape[0]))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = LeNet5()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51400a17-9566-49f8-b441-1313fb75a9e5",
      "metadata": {
        "id": "51400a17-9566-49f8-b441-1313fb75a9e5",
        "outputId": "d09c7939-50e5-4ca4-b601-d277860cfc8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight :  torch.float32\n",
            "conv1.bias :  torch.float32\n",
            "conv2.weight :  torch.float32\n",
            "conv2.bias :  torch.float32\n",
            "fc1.weight :  torch.float32\n",
            "fc1.bias :  torch.float32\n",
            "fc2.weight :  torch.float32\n",
            "fc2.bias :  torch.float32\n",
            "fc3.weight :  torch.float32\n",
            "fc3.bias :  torch.float32\n"
          ]
        }
      ],
      "source": [
        "for n, p in model.named_parameters():\n",
        "    print(n, \": \", p.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb6167cb-96c6-4470-86c3-b671bee4fe2c",
      "metadata": {
        "id": "cb6167cb-96c6-4470-86c3-b671bee4fe2c",
        "outputId": "0be8fa02-07e8-4680-927b-a1fca6be7e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight :  torch.float16\n",
            "conv1.bias :  torch.float16\n",
            "conv2.weight :  torch.float16\n",
            "conv2.bias :  torch.float16\n",
            "fc1.weight :  torch.float16\n",
            "fc1.bias :  torch.float16\n",
            "fc2.weight :  torch.float16\n",
            "fc2.bias :  torch.float16\n",
            "fc3.weight :  torch.float16\n",
            "fc3.bias :  torch.float16\n"
          ]
        }
      ],
      "source": [
        "# простейший способ - half\n",
        "model = model.half()\n",
        "\n",
        "for n, p in model.named_parameters():\n",
        "    print(n, \": \", p.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d51d2c-1e9e-4495-83c5-b91da13df57f",
      "metadata": {
        "id": "28d51d2c-1e9e-4495-83c5-b91da13df57f"
      },
      "source": [
        "Есть ещё другие способы квантизации:\n",
        "\n",
        "- dynamic quantization\n",
        "- post-training static quantization\n",
        "- quantization-aware training (QAT)\n",
        "\n",
        "Что-то может поддерживаться только для CPU (читайте документацию)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ad6f39-7074-4e6f-8ade-42657d368e47",
      "metadata": {
        "id": "87ad6f39-7074-4e6f-8ade-42657d368e47"
      },
      "outputs": [],
      "source": [
        "# динамическая\n",
        "\n",
        "import torch.quantization\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(model,  {torch.nn.Linear}, dtype=torch.qint8) # указываем слои для квантизации и до какого уровня её провести"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d21d344-9965-4e9f-a93c-991e24b64c1b",
      "metadata": {
        "id": "6d21d344-9965-4e9f-a93c-991e24b64c1b"
      },
      "outputs": [],
      "source": [
        "# post-training static quantization\n",
        "\n",
        "static_quant_model = LeNet5()\n",
        "static_quant_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "\n",
        "torch.quantization.prepare(static_quant_model, inplace=True)\n",
        "torch.quantization.convert(static_quant_model, inplace=True) # to quantize the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f914e3-11ec-4a3e-9c64-c50069acaee5",
      "metadata": {
        "id": "05f914e3-11ec-4a3e-9c64-c50069acaee5"
      },
      "outputs": [],
      "source": [
        "# quantization-aware training (QAT)\n",
        "\n",
        "qat_model = LeNet5()\n",
        "qat_mode.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "\n",
        "torch.quantization.prepare_qat(qat_model, inplace=True)\n",
        "torch.quantization.convert(qat_model, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea4db22d-06d9-4dbe-8e54-6fc0ed3a866c",
      "metadata": {
        "id": "ea4db22d-06d9-4dbe-8e54-6fc0ed3a866c"
      },
      "source": [
        "# Pruning\n",
        "\n",
        "Можно, кстати, задать и свой метод пранинга."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308a045a-6060-4e55-a543-962f2b531d1e",
      "metadata": {
        "id": "308a045a-6060-4e55-a543-962f2b531d1e"
      },
      "outputs": [],
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "prune.random_unstructured(model.conv1,\n",
        "                          name=\"weight\",\n",
        "                          amount=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "519fef64-a59c-4e63-b6a4-5a71b3d3ad9b",
      "metadata": {
        "id": "519fef64-a59c-4e63-b6a4-5a71b3d3ad9b"
      },
      "outputs": [],
      "source": [
        "# последовательно\n",
        "\n",
        "model = LeNet5().to(device)\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        prune.random_unstructured(module,\n",
        "                              name='weight',\n",
        "                              amount=0.3)\n",
        "    elif isinstance(module, torch.nn.Linear):\n",
        "        prune.random_unstructured(module,\n",
        "                              name='weight',\n",
        "                              amount=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18ea3ec1-1e48-4724-a4a1-af3ad2c29c51",
      "metadata": {
        "id": "18ea3ec1-1e48-4724-a4a1-af3ad2c29c51"
      },
      "outputs": [],
      "source": [
        "# глобальный пранинг\n",
        "\n",
        "model = LeNet5().to(device)\n",
        "\n",
        "parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        "    (model.fc3, 'weight'),\n",
        ")\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7bd7a6d-7267-4818-9312-2e5963c991e0",
      "metadata": {
        "id": "a7bd7a6d-7267-4818-9312-2e5963c991e0"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fedbf4b1-660c-437c-adeb-8619f6fd5a2a",
      "metadata": {
        "id": "fedbf4b1-660c-437c-adeb-8619f6fd5a2a"
      },
      "outputs": [],
      "source": [
        "pip install tensorboard\n",
        "conda install tensorboard\n",
        "\n",
        "# TensorBoard can then be started on the command line:\n",
        "tensorboard --logdir=runs\n",
        "# You can then go to http://[your-machine]:6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60dc5906-7b10-49fc-ae6a-e9088b6f52a0",
      "metadata": {
        "id": "60dc5906-7b10-49fc-ae6a-e9088b6f52a0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "writer.add_scalar('example', 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71f9b90-4db9-4ebd-9c46-323e54470eda",
      "metadata": {
        "id": "a71f9b90-4db9-4ebd-9c46-323e54470eda"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "value = 10\n",
        "writer.add_scalar('test_loop', value, 0)\n",
        "for i in range(1,10000):\n",
        "    value += random.random() - 0.5\n",
        "    writer.add_scalar('test_loop', value, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e9a410-123f-41cd-bf2b-35c0ae9cee06",
      "metadata": {
        "id": "03e9a410-123f-41cd-bf2b-35c0ae9cee06"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms,models\n",
        "\n",
        "writer = SummaryWriter()\n",
        "model = models.resnet18(False)\n",
        "writer.add_graph(model, torch.rand([1,3,224,224]))\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_data_loader, test_data_loader, epochs=20):\n",
        "    model = model.train()\n",
        "    iteration = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input, target = batch\n",
        "            output = model(input)\n",
        "            loss = loss_fn(output, target)\n",
        "            writer.add_scalar('loss', loss, epoch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "\n",
        "        for batch in val_loader:\n",
        "            input, target = batch\n",
        "            output = model(input)\n",
        "            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], target).view(-1)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "        print(\"Epoch {}, accuracy = {:.2f}\".format(epoch, num_correct / num_examples) # ? ->\n",
        "        writer.add_scalar('accuracy', num_correct / num_examples, epoch) # ? ->\n",
        "        iterations += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "594b40e1-5a85-47ab-8cbd-b636f39d806d",
      "metadata": {
        "id": "594b40e1-5a85-47ab-8cbd-b636f39d806d"
      },
      "source": [
        "##  Hooks\n",
        "\n",
        "функции, которые могут быть приписаны к тензорам и вызываются при проходах: прямом или обратном"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dff02b53-ef43-4094-999f-8bd97114c6a6",
      "metadata": {
        "id": "dff02b53-ef43-4094-999f-8bd97114c6a6"
      },
      "outputs": [],
      "source": [
        "def print_hook(self, module, input, output):\n",
        "    print(f\"Shape of input is {input.shape}\")\n",
        "\n",
        "model = models.resnet18()\n",
        "hook_ref = model.fc.register_forward_hook(print_hook) # для обратного прохода register_backward_hook()\n",
        "model(torch.rand([1,3,224,224]))\n",
        "hook_ref.remove()\n",
        "model(torch.rand([1,3,224,224]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54f94dd9-30fd-4a7e-9cd4-f6656a27d706",
      "metadata": {
        "id": "54f94dd9-30fd-4a7e-9cd4-f6656a27d706"
      },
      "outputs": [],
      "source": [
        "def send_stats(i, module, input, output):\n",
        "    writer.add_scalar(f\"{i}-mean\",output.data.std()) # посылаем статистику в TB\n",
        "    writer.add_scalar(f\"{i}-stddev\",output.data.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e100cea1-5f9c-46d5-8175-42045a8631ee",
      "metadata": {
        "id": "e100cea1-5f9c-46d5-8175-42045a8631ee"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "for i,m in enumerate(model.children()):\n",
        "    m.register_forward_hook(partial(send_stats, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "325e0e6a-6a5f-41da-895a-52edd3b49fd7",
      "metadata": {
        "id": "325e0e6a-6a5f-41da-895a-52edd3b49fd7"
      },
      "outputs": [],
      "source": [
        "# Class Activation Mapping\n",
        "\n",
        "class SaveActivations():\n",
        "    activations=None\n",
        "    def __init__(self, m):\n",
        "        self.hook = m.register_forward_hook(self.hook_fn)\n",
        "\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.features = output.data\n",
        "\n",
        "    def remove(self):\n",
        "        self.hook.remove()\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "x_activations = SaveActivations(model.layer_4)\n",
        "prediction = model(x.unsqueeze(0))\n",
        "pred_probabilities = F.softmax(prediction).data.squeeze()\n",
        "x_activations.remove()\n",
        "torch.topk(pred_probabilities,1)\n",
        "\n",
        "\n",
        "# ?\n",
        "fts = sf[0].features[idx]\n",
        "prob = np.exp(to_np(log_prob))\n",
        "preds = np.argmax(prob[idx])\n",
        "fts_np = to_np(fts)\n",
        "f2=np.dot(np.rollaxis(fts_np,0,3), prob[idx])\n",
        "f2-=f2.min()\n",
        "f2/=f2.max()\n",
        "f2\n",
        "plt.imshow(dx)\n",
        "plt.imshow(scipy.misc.imresize(f2, dx.shape), alpha=0.5, cmap='jet');\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# по умолчанию в вычислительном графе градиенты вычисляются для листьев\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([2.], requires_grad=True)\n",
        "y = x * x\n",
        "z = y * y\n",
        "\n",
        "y.register_hook(print) # теперь градиент пропечатается\n",
        "\n",
        "y.retain_grad() # без этого градиент не выведется, т.к. это не лист\n",
        "\n",
        "z.backward()\n",
        "\n",
        "print(y.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQZthfSEctzr",
        "outputId": "7afd98ca-7cda-47df-ad98-f9f5bdd83f9d"
      },
      "id": "LQZthfSEctzr",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8.])\n",
            "tensor([8.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация L1-регуляризации с помощью хуков\n",
        "\n",
        "См. https://stackoverflow.com/questions/42704283/l1-l2-regularization-in-pytorch"
      ],
      "metadata": {
        "id": "NtHu8ompcro1"
      },
      "id": "NtHu8ompcro1"
    },
    {
      "cell_type": "code",
      "source": [
        "# вызов layer = L1(torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3))\n",
        "\n",
        "class L1(torch.nn.Module):\n",
        "    def __init__(self, module, weight_decay):\n",
        "        super().__init__()\n",
        "        self.module = module\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "        # Backward hook is registered on the specified module\n",
        "        self.hook = self.module.register_full_backward_hook(self._weight_decay_hook)\n",
        "\n",
        "    # Not dependent on backprop incoming values, placeholder\n",
        "    def _weight_decay_hook(self, *_):\n",
        "        for param in self.module.parameters():\n",
        "            # If there is no gradient or it was zeroed out\n",
        "            # Zeroed out using optimizer.zero_grad() usually\n",
        "            # Turn on if needed with grad accumulation/more safer way\n",
        "            # if param.grad is None or torch.all(param.grad == 0.0):\n",
        "\n",
        "            # Apply regularization on it\n",
        "            param.grad = self.regularize(param)\n",
        "\n",
        "    def regularize(self, parameter):\n",
        "        # L1 regularization formula\n",
        "        return self.weight_decay * torch.sign(parameter.data)\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        # Simply forward and args and kwargs to module\n",
        "        return self.module(*args, **kwargs)"
      ],
      "metadata": {
        "id": "BJRYcL7-cyw3"
      },
      "id": "BJRYcL7-cyw3",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L1-регуляризация активаций!\n",
        "import torch\n",
        "\n",
        "\n",
        "class OutputHook(list):\n",
        "    \"\"\" Hook to capture module outputs.\n",
        "    \"\"\"\n",
        "    def __call__(self, module, input, output):\n",
        "        self.append(output)\n",
        "\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(128, 32)\n",
        "        self.linear2 = torch.nn.Linear(32, 16)\n",
        "        self.linear3 = torch.nn.Linear(16, 2)\n",
        "        # Instantiate ReLU, so a hook can be registered to capture its output.\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        layer1_out = self.relu(self.linear1(x))\n",
        "        layer2_out = self.relu(self.linear2(layer1_out))\n",
        "        out = self.linear3(layer2_out)\n",
        "        return out\n",
        "\n",
        "\n",
        "batch_size = 4\n",
        "l1_lambda = 0.01\n",
        "\n",
        "model = MLP()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
        "# Register hook to capture the ReLU outputs. Non-trivial networks will often\n",
        "# require hooks to be applied more judiciously.\n",
        "output_hook = OutputHook()\n",
        "model.relu.register_forward_hook(output_hook)\n",
        "\n",
        "inputs = torch.rand(batch_size, 128)\n",
        "targets = torch.ones(batch_size).long()\n",
        "\n",
        "optimizer.zero_grad()\n",
        "outputs = model(inputs)\n",
        "cross_entropy_loss = torch.nn.functional.cross_entropy(outputs, targets)\n",
        "\n",
        "# Compute the L1 penalty over the ReLU outputs captured by the hook.\n",
        "l1_penalty = 0.\n",
        "for output in output_hook:\n",
        "    l1_penalty += torch.norm(output, 1)\n",
        "l1_penalty *= l1_lambda\n",
        "\n",
        "loss = cross_entropy_loss + l1_penalty\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "output_hook.clear()"
      ],
      "metadata": {
        "id": "NeMXmK8H6z5L"
      },
      "id": "NeMXmK8H6z5L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  БЕЗ ХУКОВ\n",
        "# + самописные L1 И L2 регуляризации\n",
        "\n",
        "optimizer.zero_grad()\n",
        "outputs, layer1_out, layer2_out = model(inputs)\n",
        "cross_entropy_loss = F.cross_entropy(outputs, targets)\n",
        "\n",
        "all_linear1_params = torch.cat([x.view(-1) for x in model.linear1.parameters()])\n",
        "all_linear2_params = torch.cat([x.view(-1) for x in model.linear2.parameters()])\n",
        "l1_regularization = lambda1 * torch.norm(all_linear1_params, 1)\n",
        "l2_regularization = lambda2 * torch.norm(all_linear2_params, 2)\n",
        "\n",
        "loss = cross_entropy_loss + l1_regularization + l2_regularization\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "# или так\n",
        "\n",
        "l1_regularization, l2_regularization = torch.tensor(0), torch.tensor(0)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "outputs = model(inputs)\n",
        "cross_entropy_loss = F.cross_entropy(outputs, targets)\n",
        "for param in model.parameters():\n",
        "    l1_regularization += torch.norm(param, 1)**2\n",
        "    l2_regularization += torch.norm(param, 2)**2\n",
        "\n",
        "loss = cross_entropy_loss + l1_regularization + l2_regularization\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "rVVSjxqC7pbR"
      },
      "id": "rVVSjxqC7pbR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "34577cf9-f7f5-409c-a22e-72b82ea60927",
      "metadata": {
        "id": "34577cf9-f7f5-409c-a22e-72b82ea60927"
      },
      "source": [
        "## Label Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fc09b4-ca4c-4ecd-86e9-6c2e52dff825",
      "metadata": {
        "id": "d1fc09b4-ca4c-4ecd-86e9-6c2e52dff825"
      },
      "outputs": [],
      "source": [
        "class LabelSmoothingCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, epsilon=0.1):\n",
        "        super(LabelSmoothingCrossEntropyLoss, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        num_classes = output.size()[-1]\n",
        "        log_preds = F.log_softmax(output, dim=-1)\n",
        "        loss = (-log_preds.sum(dim=-1)).mean()\n",
        "        nll = F.nll_loss(log_preds, target)\n",
        "        final_loss = self.epsilon * loss / num_classes + (1-self.epsilon) * nll\n",
        "        return final_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108b25d6-5c73-4ff6-a079-5b02030319a4",
      "metadata": {
        "id": "108b25d6-5c73-4ff6-a079-5b02030319a4"
      },
      "source": [
        "## FGSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "040107f3-bedb-4379-929c-88cda5e73def",
      "metadata": {
        "id": "040107f3-bedb-4379-929c-88cda5e73def"
      },
      "outputs": [],
      "source": [
        "def fgsm(input_tensor, labels, epsilon=0.02, loss_function, model):\n",
        "    outputs = model(input_tensor)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward(retain_graph=True)\n",
        "    fsgm = torch.sign(inputs.grad) * epsilon\n",
        "    return fgsm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc62eac-215f-4569-a75d-ef64385222a1",
      "metadata": {
        "id": "7fc62eac-215f-4569-a75d-ef64385222a1"
      },
      "outputs": [],
      "source": [
        "model_to_break = # load our model to break here\n",
        "adversarial_mask = fgsm(frog_image.unsqueeze(-1),\n",
        "                        batch_labels,\n",
        "                        loss_function,\n",
        "                        model_to_break)\n",
        "adversarial_image = adversarial_mask.squeeze(0) + frog_image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c8918d7-ff6c-48f3-93c8-845ab4bb9065",
      "metadata": {
        "id": "3c8918d7-ff6c-48f3-93c8-845ab4bb9065"
      },
      "source": [
        "## Другое"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f60c93a2-156c-4525-91ae-2986f9a76166",
      "metadata": {
        "id": "f60c93a2-156c-4525-91ae-2986f9a76166",
        "outputId": "f908fbf4-a5c7-473f-ff5d-71ff83323883"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"nvidia-smi\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
            "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d475169-6f71-4a77-b404-79a115802e88",
      "metadata": {
        "id": "5d475169-6f71-4a77-b404-79a115802e88"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "del tensor_to_be_deleted\n",
        "gc.collect()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b06e73f-de3d-4465-9edf-19b9bc6877e6",
      "metadata": {
        "id": "4b06e73f-de3d-4465-9edf-19b9bc6877e6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Показ изображений"
      ],
      "metadata": {
        "id": "kmPxwDdn9ikd"
      },
      "id": "kmPxwDdn9ikd"
    },
    {
      "cell_type": "code",
      "source": [
        "# показать изображение\n",
        "\n",
        "plt.imshow(  tensor_image.permute(1, 2, 0)  ) # permute не выделяет память\n",
        "\n",
        "plt.imshow(transforms.ToPILImage()(image), interpolation=\"bicubic\")\n",
        "#transforms.ToPILImage()(image).show() # Alternatively\n",
        "\n",
        "\n",
        "#\n",
        "\n",
        "    def show(img):\n",
        "        npimg = img.numpy()\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
        "\n",
        "\n",
        "##### test_image = Image.open(test_image_name).convert('RGB')"
      ],
      "metadata": {
        "id": "6m3bFMVN9lB0"
      },
      "id": "6m3bFMVN9lB0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}