{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwyQjWD7sNhC"
      },
      "source": [
        "# Введение в Pytorch\n",
        "\n",
        "## Часть 1 - тензоры, GPU, автодифференцирование\n",
        "\n",
        "Александр Дьяконов, 2020-22\n",
        "\n",
        "\n",
        "#### использованные материалы\n",
        "\n",
        "* https://github.com/MLWhiz/data_science_blogs/blob/master/pytorch_guide/Pytorch%20Guide.ipynb\n",
        "* https://d2l.ai/\n",
        "* https://atcold.github.io/pytorch-Deep-Learning/\n",
        "* семинары OzonMasters\n",
        "* https://habr.com/ru/post/334380/\n",
        "* https://github.com/andriygav/MachineLearningSeminars/\n",
        "* https://uvadlc-notebooks.readthedocs.io/en/latest/index.html\n",
        "* книга Joe Papa \"PyTorch Pocket Reference\" 2021, https://github.com/joe-papa/pytorch-book\n",
        "* https://github.com/vahidk/EffectivePyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i94DdIIjsNhE"
      },
      "source": [
        "**Pytorch** - открытый фреймворк для построения и использования динамических графов вычислений и глубокого обучения. Есть альтернативы: [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax#quickstart-colab-in-the-cloud), [Caffe](http://caffe.berkeleyvision.org/). Изначально разрабатывался Fecebook’s AI Research Lab (FAIR). Вместе с функционалом Python удобен для экспериментов и разработки (минимум кода при максимуме возможностей). Наиболее важные для DL возможности:\n",
        "\n",
        "- автоматическое дифференцирование,\n",
        "- вычисления на базе многомерных матриц (тензоров) - очень похож на numpy,\n",
        "- поддержка динамических вычислительных графов (создаются при работе),\n",
        "- поддержка вычислений на GPU,\n",
        "- есть полезные модули (например, torchvision).\n",
        "\n",
        "Про установку см. на официальном сайте https://pytorch.org/get-started/locally/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb_QcJOWsNhG"
      },
      "outputs": [],
      "source": [
        "# from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# что разумно сразу импортировать\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRVhjXu3sNhH"
      },
      "outputs": [],
      "source": [
        "# для автодополнения\n",
        "%config Completer.use_jedi = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFexn2ccsNhH"
      },
      "source": [
        "## Помощь, общие моменты, Colab\n",
        "\n",
        "- по умолчанию вычисления на Colab используют CPU. Не забудьте включить GPU!\n",
        "- есть платная версия Colab Pro (там больше возможностей, например более быстрые GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPrlvKw-sNhI"
      },
      "outputs": [],
      "source": [
        "# основная помощь\n",
        "torch.nn.Module?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbXbVafxsNhJ"
      },
      "outputs": [],
      "source": [
        "# + код функции\n",
        "torch.nn.Module??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzRI4m0DsNhJ",
        "outputId": "e0a5c53c-d3a8-496d-dcd9-d906bac0c49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.8.8\n",
            "1.9.0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Проверка версии питона, пайторча и доступности видеокарты\n",
        "import torch # заметьте, что не import pytorch\n",
        "from platform import python_version\n",
        "print(python_version()) # 3.8.8\n",
        "print(torch.__version__) # 1.9.0\n",
        "print (torch.cuda.is_available()) # True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XF1MNTTsNhK"
      },
      "outputs": [],
      "source": [
        "# COLAB - прикручиваем свой гуглдиск\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "% cd '/content/drive/My Drive/'\n",
        "\n",
        "data_path = \"/content/gdrive/My Drive/Colab Notebooks/name/\"\n",
        "train_ann_path = data_path + 'train.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_ann_path)\n",
        "print(train_df.head())\n",
        "\n",
        "# команды для bash пишутся с !\n",
        "!ls /content/gdrive/My\\ Drive/Colab\\ Notebooks/name/\n",
        "\n",
        "# ПОТОМ ПЕРЕДЕЛАТЬ!!!!!\n",
        "# разархивируем, -q - не выводить логи\n",
        "!unzip -q /content/gdrive/My\\ Drive/Colab\\ Notebooks/05.\\ Real\\ data/signs/train.zip -d ./\n",
        "\n",
        "print(len(os.listdir('./train/')))\n",
        "print(len(os.listdir('./test/')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpznZkzCsNhM"
      },
      "source": [
        "## Тензоры\n",
        "\n",
        "Тензоры (torch.Tensor) - аналоги многомерных массивов пакета numpy, только\n",
        "- могут располагаться на GPU (или поддерживать вычисления на нескольких CPU),\n",
        "- могут быть элементами вычислительного графа и поддерживать автоматическое дифференцирование (об этом позже).\n",
        "\n",
        "Это фундаментальная структура данных в Pytorch (с помощью неё будут храниться и обрабатываться объекты: тексты, сигналы изображения и батчи - наборы объектов). Могут в многомерном матричном виде хранить данные определённого типа.\n",
        "\n",
        "**темы ниже**\n",
        "* индексация\n",
        "* получение одного из других\n",
        "* размеры\n",
        "* операции\n",
        "* статистики\n",
        "* связь с Numpy\n",
        "* сохранение и загрузка\n",
        "* примеры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYLcMVIjsNhN"
      },
      "source": [
        "### Тензоры: создание"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hp26msTsNhO",
        "outputId": "ec5029c6-aafd-4e12-b785-657990638a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]]) \n",
            " torch.Size([2, 3]) \n",
            " torch.int64 \n",
            " cpu \n",
            " torch.LongTensor \n",
            " 2 \n",
            " torch.Size([2, 3]) \n",
            " 6\n"
          ]
        }
      ],
      "source": [
        "# создание тензора из списка (аналогично можно использовать кортеж, np.array)\n",
        "# по умолчанию тензор создаётся на CPU, а тип его элементов определяется автоматически\n",
        "\n",
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(x, '\\n',\n",
        "      x.shape, '\\n', # размер тензора\n",
        "      x.dtype, '\\n', # тип\n",
        "      x.device, '\\n', # где лежит\n",
        "      x.type(), '\\n', # тип\n",
        "      x.dim(), '\\n', # размерность\n",
        "      x.size(), '\\n', # размер тензора; .shape и .size() одно и то же\n",
        "      x.numel()) # тип тензора"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print (torch.Tensor([1, 2, 3]).dtype)  # Создаёт тензор с типом по умолчанию, как в  torch.get_default_dtype()\n",
        "# torch.float32\n",
        "print (torch.tensor([1, 2, 3]).dtype) # Пытается понять тип по данным\n",
        "# torch.int64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7WlV_P2vNkT",
        "outputId": "ee533a3b-816b-4cbe-e7d8-f1fd7e6e97fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78Bz0lVRsNhP",
        "outputId": "cd9385d8-f260-4240-c21a-f247505bcca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) \n",
            " 2668314180416 \n",
            " 2668314185344\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor(2, 3)\n",
        "y = torch.Tensor(2, 3) # эквивалентно предыдущей записи (когда используется заглавная T)\n",
        "print (x, '\\n', y, '\\n', x.data_ptr(), '\\n', y.data_ptr()) # + где лежит в памяти"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ejDRV7-sNhQ",
        "outputId": "773dae25-da20-42e2-fc15-7917b5a35656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "x = torch.cuda.FloatTensor(2, 3) # те тензоры были на CPU\n",
        "print (x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnrxgGL2sNhQ",
        "outputId": "abcdcc0f-905e-4e4b-80ca-5ed057a2743f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2.])\n",
            "tensor([1., 2.], dtype=torch.float64)\n",
            "tensor([1., 2.])\n"
          ]
        }
      ],
      "source": [
        "# приведение типов\n",
        "\n",
        "x = torch.IntTensor([1, 2]).float()\n",
        "print (x)\n",
        "\n",
        "x = torch.IntTensor([1, 2]).to(torch.float64)\n",
        "print (x)\n",
        "\n",
        "x = torch.IntTensor([1, 2]) + 0.0 #\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAoZtj4XsNhR"
      },
      "source": [
        "Во всех функциях создания тензоров (ниже) есть параметры dtype - тип элементов тензора и device - где размещать тензор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVvM2V1vsNhS",
        "outputId": "efdcce4e-7c87-4e73-a7db-16d6475e4cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[8.9082e-39, 5.9694e-39, 8.9082e-39, 1.0194e-38, 9.1837e-39],\n",
            "        [4.6837e-39, 9.9184e-39, 9.0000e-39, 1.0561e-38, 1.0653e-38],\n",
            "        [4.1327e-39, 8.9082e-39, 9.8265e-39, 9.4592e-39, 1.0561e-38]])\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[3.1400, 3.1400, 3.1400, 3.1400, 3.1400],\n",
            "        [3.1400, 3.1400, 3.1400, 3.1400, 3.1400],\n",
            "        [3.1400, 3.1400, 3.1400, 3.1400, 3.1400]])\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.]])\n",
            "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740],\n",
            "        [0.8665, 0.1366, 0.1025, 0.1841, 0.7264],\n",
            "        [0.3153, 0.6871, 0.0756, 0.1966, 0.3164]])\n",
            "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
            "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085],\n",
            "        [ 0.2103, -0.3908,  0.2350,  0.6653,  0.3528]])\n",
            "tensor([[2, 3, 2, 2, 2],\n",
            "        [2, 2, 3, 3, 2],\n",
            "        [3, 3, 2, 3, 2]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ -0.4369, -23.8010,   0.2966,  -3.3384,  -0.0868],\n",
              "        [  0.0693,   0.3427,   0.0986,   6.1324,  -5.5569],\n",
              "        [  1.6738,  -3.2946,  -1.4137,  -1.2062,  -1.4264]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# пустая матрица (тензор)\n",
        "x = torch.empty(3, 5)\n",
        "print(x)\n",
        "\n",
        "# матрица из 1\n",
        "x = torch.ones(3, 5)\n",
        "print(x)\n",
        "\n",
        "# матрица из 0\n",
        "x = torch.zeros(3, 5)\n",
        "print(x)\n",
        "\n",
        "# матрица из 3.14\n",
        "x = torch.full((3, 5), 3.14, dtype=torch.float)\n",
        "print(x)\n",
        "\n",
        "# единичная матрица (с единицами на главной диагонали)\n",
        "x = torch.eye(3, 5)\n",
        "print(x)\n",
        "\n",
        "# случайная матрица c элементами равномерно распределёнными на [0, 1]\n",
        "torch.manual_seed(123)\n",
        "x = torch.rand(3, 5)\n",
        "print(x)\n",
        "\n",
        "# случайная матрица c нормально распределёнными элементами\n",
        "torch.manual_seed(123)\n",
        "x = torch.randn(3, 5)\n",
        "print(x)\n",
        "\n",
        "# случайная матрица c числами от 2 до 4 (не включая)\n",
        "torch.manual_seed(123)\n",
        "x = torch.randint(2, 4, (3, 5))\n",
        "print(x)\n",
        "\n",
        "# а вот так с распределением Коши\n",
        "torch.manual_seed(123)\n",
        "torch.empty((3, 5)).cauchy_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGRb8oqUsNhT",
        "outputId": "919a216a-2aef-4671-edce-a8fd05f14cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 2, 4, 6, 8])\n",
            "tensor([ 0.,  5., 10.])\n",
            "tensor([ 1.0000,  3.1623, 10.0000])\n"
          ]
        }
      ],
      "source": [
        "# \"равномерные\" массивы\n",
        "\n",
        "x = torch.arange(0, 10, 2) # аналог np.arange\n",
        "print(x)\n",
        "\n",
        "x = torch.linspace(0, 10, 3) # аналог np.linspace\n",
        "print(x)\n",
        "\n",
        "x = torch.logspace(0, 1, 3) # аналог np.logspace\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmSEjiP3sNhT",
        "outputId": "d7eb972c-58a6-4975-d8cd-3afac94acf65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0.,  5., 10.]), tensor([0., 0., 0.]), tensor([1., 1., 1.]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# сделать тензоры \"по обоазцу\" (использовать такой же тип и размеры)\n",
        "torch.empty_like(x), torch.zeros_like(x), torch.ones_like(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRK9OUJLsNhT",
        "outputId": "14d76f44-6bbb-4995-e056-209a24a1dfdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.2424, 94.9299])\n",
            "tensor([6, 0, 9, 4, 5, 8, 3, 7, 2, 1])\n"
          ]
        }
      ],
      "source": [
        "# ещё о \"случайных\" функциях\n",
        "\n",
        "x = torch.normal(mean=torch.tensor([0., 100.]), std=torch.tensor([1., 10.])) # выборка из нормальных распределений\n",
        "print(x)\n",
        "\n",
        "x = torch.randperm(10) # случайная перестановка\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW\n",
        "\n",
        "t = torch.randn((3, 4))\n",
        "a = t.new_tensor([1, 2, 3])  # такие же type, device, но новые данные\n",
        "b = t.new_empty((3, 4))      # такие же type, device, без инициализации\n",
        "c = t.new_zeros((2, 3))      # такие же type, device, заполняем нулями"
      ],
      "metadata": {
        "id": "LVfmIEmzbqrY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYetaTM2sNhU"
      },
      "source": [
        "### Тензоры: индексация\n",
        "\n",
        "Индексация аналогичная принятой в питоне, в частрости в numpy: [start:end:step]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypdGHtGxsNhU",
        "outputId": "55833ca9-a647-4fed-ee32-16602f79c0a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([6, 5, 3, 9, 4]),\n",
              " tensor([6, 5, 3, 9, 4]),\n",
              " tensor([[6, 5, 3, 9, 4]]),\n",
              " tensor([[6, 5, 3, 9, 4]]))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randint(0, 10, (2, 5))\n",
        "\n",
        "x[0], x[0, :], x[[0], :], x[:1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yRKsiS3sNhU",
        "outputId": "414e99f5-56f0-42d5-8c66-e080010b420e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[5],\n",
              "         [1]]),\n",
              " tensor([5, 1]),\n",
              " tensor([5, 1]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:,[1]], x[:, 1], x[:, -4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k96LmncfsNhV",
        "outputId": "c7915ec7-bf3e-439f-ef07-b8af638ca044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6)\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "print (x[0, 0]) # это тензор 1х1\n",
        "print (x[0, 0].item()) # а это уже отдельный элемент"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNMYppBasNhV",
        "outputId": "f6201e37-1985-4b0f-cfb5-b2de7019253c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([6, 9, 6, 8])\n",
            "tensor([[ True, False, False,  True, False],\n",
            "        [ True, False,  True, False, False]])\n"
          ]
        }
      ],
      "source": [
        "print (x[x > 5]) # логическая индексация\n",
        "\n",
        "print (x > 5) # логический тензор"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# индексация\n",
        "\n",
        "import torch\n",
        "\n",
        "B = torch.LongTensor([[1, 2, 3], [4, 5, 6]])\n",
        "idx1 = torch.LongTensor([0, 2])\n",
        "idx2 = torch.BoolTensor([False, True, True])\n",
        "\n",
        "print (B)\n",
        "print (B[:, idx1])\n",
        "print (B[:, idx2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iACwo0wmPwhT",
        "outputId": "cac8cead-3703-4f64-9d24-209b2e8b57a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 3],\n",
            "        [4, 6]])\n",
            "tensor([[2, 3],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QacECpoasNhW"
      },
      "source": [
        "### Тензоры: получение одного из других\n",
        "\n",
        "Есть много способов копирования тензоров. Следует учитывать, что при использовании `clone()` копия остаётся в графе вычислений. При использовании `copy_()` такого не происходит. `detach` - убирает информацию связанную с вычислительным графом из объекта."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# копирование\n",
        "\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "b = a.new_tensor(a)\n",
        "b = a.clone().detach()\n",
        "b = torch.empty_like(a).copy_(a)\n",
        "b = torch.tensor(a)\n",
        "b = a.detach().clone() # лучше так"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0E9DBBghtIi",
        "outputId": "85fe7380-6135-49bd-a9c7-a4c644ed74c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-4bb2d404a7e5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  b = a.new_tensor(a)\n",
            "<ipython-input-8-4bb2d404a7e5>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  b = torch.tensor(a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lItnnMhMsNhX",
        "outputId": "a5cec028-e034-4644-8914-91f89aeb604e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clone\n",
            " tensor([[10,  2],\n",
            "        [ 3,  4]]) \n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "t()\n",
            " tensor([[30,  2],\n",
            "        [ 3,  4]]) \n",
            " tensor([[30,  3],\n",
            "        [ 2,  4]])\n"
          ]
        }
      ],
      "source": [
        "# клонируем - получаем другой идентичный тензор\n",
        "\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = x.clone()\n",
        "# print (id(x.storage()) == id(y.storage()))\n",
        "x[0, 0] = 10\n",
        "print ('clone\\n', x, '\\n', y)\n",
        "\n",
        "# транспонируем - не происходит копирования, используется та же память\n",
        "xt = x.t()\n",
        "x[0, 0] = 30\n",
        "print ('t()\\n', x, '\\n', xt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZGo-nJFsNhX",
        "outputId": "1b91c325-5e89-4335-cbe7-ebc2825b33b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.0283,  1.4220],\n",
            "        [-0.3886, -0.8903]])\n"
          ]
        }
      ],
      "source": [
        "# матрица такого же размера\n",
        "y = torch.randn_like(x, dtype=torch.float)\n",
        "print(y)\n",
        "\n",
        "y = torch.ones_like(x) # такие же размеры, но из единиц"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aEdH3kCsNhX",
        "outputId": "abc32980-c99c-428a-b029-5d0bde14a884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[2, 2],\n",
            "         [2, 2]]]) \n",
            " torch.Size([2, 2, 2])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            " tensor([[2, 2],\n",
            "        [2, 2]])\n",
            "tensor([[1, 2],\n",
            "        [2, 2]]) \n",
            " tensor([[3, 4],\n",
            "        [2, 2]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = torch.tensor([[2, 2], [2, 2]])\n",
        "\n",
        "z = torch.stack((x, y)) # состыковка тензоров (по умолчанию dim=0)\n",
        "print (z, '\\n', z.shape)\n",
        "\n",
        "x, y = z.unbind(dim=0) # разстыковка тензоров\n",
        "print (x, '\\n', y)\n",
        "\n",
        "x, y = z.unbind(dim=1) # разстыковка тензоров\n",
        "print (x, '\\n', y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54_PJXhMsNhY",
        "outputId": "a5c7d678-b27d-4e6c-9092-4f2ce2e03abd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 2, 2],\n",
              "         [3, 4, 2, 2]]),\n",
              " tensor([[1, 2],\n",
              "         [3, 4],\n",
              "         [2, 2],\n",
              "         [2, 2]]))"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# конкатенация по 0 и 1 размерностям\n",
        "# cat в отличие от stack использует существующие размерности\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = torch.tensor([[2, 2], [2, 2]])\n",
        "torch.cat([x, y], axis=1), torch.cat([x, y], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9DCUR07sNhY",
        "outputId": "1312cc70-7d70-4e5c-d602-55703d9ec402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 2]) torch.Size([2, 1, 2]) torch.Size([2, 2, 1])\n",
            "torch.Size([1, 2, 2]) torch.Size([2, 1, 2]) torch.Size([2, 2, 1])\n"
          ]
        }
      ],
      "source": [
        "# создание фиктивной размерности - в какую позицию вставлять фиктивную\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "print (x.unsqueeze(dim=0).shape, x.unsqueeze(dim=1).shape, x.unsqueeze(dim=2).shape)\n",
        "# другой способ ~ np.newaxis\n",
        "print (x[None, :, :].shape, x[:, None, :].shape, x[:, :, None].shape)\n",
        "\n",
        "# ??? посмотреть общую память"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnmK4OTNsNha",
        "outputId": "9f0778e5-e28a-4577-de97-106b2a29dfb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 3],\n",
            "         [2, 4]],\n",
            "\n",
            "        [[2, 2],\n",
            "         [2, 2]]])\n",
            "tensor([[[1, 3],\n",
            "         [2, 4]],\n",
            "\n",
            "        [[2, 2],\n",
            "         [2, 2]]])\n"
          ]
        }
      ],
      "source": [
        "# конкатенация по 2-й размерности\n",
        "z = torch.cat([x.unsqueeze(dim=2), y.unsqueeze(dim=2)], axis=2) # или просто использовать stack - см. выше\n",
        "print(z)\n",
        "\n",
        "# или эквивалентно и проще\n",
        "z = torch.stack((x, y), dim=2)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVSpJF-dsNha",
        "outputId": "fadb08f7-32c9-4514-f7bf-4d91df372f6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# удаляем единичные размеры\n",
        "torch.empty(3, 1, 2, 1).squeeze().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "begSAH8asNhb",
        "outputId": "b13769c8-b7d7-41f9-bef8-e64e9db7e02c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[1, 2],\n",
            "        [0, 0]]), tensor([[3, 4],\n",
            "        [0, 0]]), tensor([[5],\n",
            "        [0]]))\n",
            "(tensor([[1, 2],\n",
            "        [0, 0]]), tensor([[3, 4, 5],\n",
            "        [0, 0, 0]]))\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3, 4, 5], [0, 0, 0, 0, 0]])\n",
        "\n",
        "z = torch.chunk(x, chunks=3, dim=1) # делим на части\n",
        "print (z)\n",
        "\n",
        "z = torch.split(x, [2, 3], dim=1) # ещё способ разделения с указанием размеров - на части каких размеров делим\n",
        "print (z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC5MNO2RsNhb"
      },
      "outputs": [],
      "source": [
        "# 2do torch.gather(z, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlUHz_TUsNhb",
        "outputId": "311c51b3-533e-4103-c247-3a397456f7a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 3, 4],\n",
              "        [0, 0, 0]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3, 4, 5], [0, 0, 0, 0, 0]])\n",
        "indices = torch.tensor([0, 2, 3])\n",
        "torch.index_select(x, 1, indices) # выбираем по указанному индексу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UeZgNjIsNhb",
        "outputId": "b6b858cc-5c9e-40e3-8dcd-8dc32146fc4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 2,  3,  4,  5, 10])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3, 4, 5], [0, 0, 10, 0, 0]])\n",
        "mask = x.ge(1.5) # x > 1.5\n",
        "torch.masked_select(x, mask) # выбираем по указанной маске"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btgPcRZIsNhb",
        "outputId": "953a5d8a-0503-4a6e-dfc8-8cc5d913ace3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 3, 4],\n",
              "        [0, 0, 0]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3, 4, 5], [0, 0, 0, 0, 0]])\n",
        "torch.narrow(x, dim=1, start=1, length=3) # в какой-то размерности вырезать подтензор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDTf8rFVsNhc",
        "outputId": "76ccaea8-d215-4592-d3a6-1c0e4954bfe1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0],\n",
              "        [0, 1],\n",
              "        [0, 2],\n",
              "        [0, 3],\n",
              "        [0, 4]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.nonzero(x) # индексы ненулевых элементов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCp5UrwDsNhc",
        "outputId": "4c1e37dc-7edd-495e-94cf-9953c9a44338"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 3, 0])"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3, 4, 5], [0, 0, 0, 0, 0]])\n",
        "torch.take(x, torch.tensor([0, 2, 5])) # набрать тензор из указанных элементов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nONkbtDFsNhc",
        "outputId": "4749b42f-823d-47b1-d999-0accaa6a0d63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 0., 1.]])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# по условию выбираем элементы из 1го или 2го тензора\n",
        "torch.where(torch.tensor([[1, 2, 2], [1, 2, 1]]) == 1, torch.ones(2, 3), torch.zeros(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# повтор тензора\n",
        "\n",
        "x = torch.tensor([1, 2])\n",
        "\n",
        "print (x)\n",
        "\n",
        "print (x.repeat(3, 2))\n",
        "\n",
        "print (x.repeat(2, 1, 2).shape) # Обратите внимание! Тут нетривиальный результат!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXEUcaN6-OyD",
        "outputId": "94a066af-4a84-49fd-8a48-ad61cefc28c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2])\n",
            "tensor([[1, 2, 1, 2],\n",
            "        [1, 2, 1, 2],\n",
            "        [1, 2, 1, 2]])\n",
            "torch.Size([2, 1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"Смежность\" тензора\n",
        "\n",
        "Разберёмся, как хранятся в памяти двухмерные тензоры."
      ],
      "metadata": {
        "id": "vO_Jq6tybvvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "H = torch.rand((10000, 10000))"
      ],
      "metadata": {
        "id": "jEZ-5RMob662"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "s = torch.sum(H, axis=1) # суммы строк быстрее"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJLLGmMRb93e",
        "outputId": "37d9ebfe-5949-422e-93f3-4984ecdba84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 36.8 ms, sys: 1.87 ms, total: 38.6 ms\n",
            "Wall time: 85.7 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "s = torch.sum(H, axis=0) # суммы столбцов медленнее"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neZM6amNcDQ_",
        "outputId": "06cf0831-c456-49fe-ed54-44f41178c74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 94.6 ms, sys: 0 ns, total: 94.6 ms\n",
            "Wall time: 106 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Они по умолчанию лежат \"по стокам\" - такое размещение и называется \"смежным\". Однако, например, в случае транспонирования тензора, данные не копируются, Pytorch просто запоминает, что теперь размещение \"несмежное\"."
      ],
      "metadata": {
        "id": "ZDhco3TLc5KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 2)\n",
        "print (x.is_contiguous()) # contiguous\n",
        "y = torch.transpose(x, 0, 1)\n",
        "print (x.is_contiguous()) # НЕ contiguous\n",
        "x[0, 0] = 42  # но они делят память\n",
        "print(y[0,0]) # 42"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2PWnlm-cI8l",
        "outputId": "354a037e-cd2a-4959-d563-558861c46b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "tensor(42.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oki6Ad1ssNhd"
      },
      "source": [
        "### Тензоры: размеры\n",
        "\n",
        "Можно менять \"представление\" тензора с помощью **view**, фактически это изменение размеров, но реально данные не перемещаются, pytorch просто запоминает, что тензор, заданный элементами, лежащими в определённой области памяти, имеет другрой размер.# inplace\n",
        "y.add_(x)\n",
        "\n",
        "При использовании **view** может выдаваться сообщение об ошибке - если нельзя использовать эту область памяти (можно тогда сделать предварительно **.contiguous()**).\n",
        "\n",
        "При **reshape()** тензор может копироваться."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsGCmlnDsNhd",
        "outputId": "ff559163-fbc2-4e25-dd48-7dac7df602a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0, 1],\n",
              "         [2, 3],\n",
              "         [4, 5],\n",
              "         [6, 7]]),\n",
              " tensor([[0, 1, 2, 3],\n",
              "         [4, 5, 6, 7]]))"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(8)\n",
        "\n",
        "x.view(4, 2), x.view(2, -1) # если указывается размер (-1), то он определяется автоматически, так чтобы сохранить число элементов тензора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIFcgAu4sNhe",
        "outputId": "285e7342-b4c1-431c-d0be-c09fe14d9039"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x # заметим, что сам тензор не поменялся"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OKZ2dZFsNhf",
        "outputId": "84e730c2-cbec-4fc8-fdaa-5a9663029330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7]])\n"
          ]
        }
      ],
      "source": [
        "# чтобы размер поменялся надо выполнить присваивание\n",
        "x = x.view(4, 2)\n",
        "\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Kl7E34SsNhf",
        "outputId": "946db701-5564-47aa-dd0b-267ef151f7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7]])  0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            " 6\n",
            " 7\n",
            "[torch.LongStorage of size 8] (2, 1) (1, 2)\n"
          ]
        }
      ],
      "source": [
        "# как хранятся данные, где следующий элемент по каждой из разметностей\n",
        "print (x, x.storage(), x.stride(), x.t().stride())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG7LaXDIsNhf",
        "outputId": "77831bf4-e1b3-413e-f16b-6d07e3d3cfe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 2, 4, 6],\n",
              "        [1, 3, 5, 7]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# С помощью permute можно переставлять размерности тензора, например транспозиция матрицы выполняется так:\n",
        "x.permute(1, 0) # torch.transpose(x, dim0=0, dim1=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIgR4C1rsNhg",
        "outputId": "b0612ff7-3c43-49e6-b19c-4630d16352cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 2, 3])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z = torch.rand(1, 2, 3, 4)\n",
        "z = z.permute(0, 3, 1, 2) # NxHxWxC -> NxCxHxW\n",
        "z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAdk8tbhsNhg",
        "outputId": "0a31d6d9-8b5d-48c6-824e-18e7434c7f07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0, 2, 4, 6],\n",
              "         [1, 3, 5, 7]]),\n",
              " tensor([[0, 2, 4, 6],\n",
              "         [1, 3, 5, 7]]),\n",
              " tensor([[0, 2, 4, 6],\n",
              "         [1, 3, 5, 7]]))"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# другие способы транспонирования:\n",
        "x.transpose(0, 1), x.t(), x.t_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4cce8SZsNhh",
        "outputId": "0413156f-2940-4fb0-c5e0-d70776eca3f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 2, 4, 6, 1, 3, 5, 7])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# векторизация\n",
        "x.flatten() # ещё вариант .view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_seXMjIsNhi",
        "outputId": "5f4f95a1-c3b9-431e-9570-c0dc6d490ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2]) torch.Size([4]) torch.Size([2, 1, 2]) torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "# view vs reshape\n",
        "x = torch.rand(2, 2)\n",
        "\n",
        "a = x.view(4)\n",
        "b = x.view(2, 1, -1)\n",
        "\n",
        "y  = x.reshape(1, 4)\n",
        "\n",
        "print (x.size(), a.size(), b.size(), y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFxlXSJzsNhi",
        "outputId": "5ab2b58e-422e-45a1-9e57-18970559b532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "смежность True\n",
            "вытягиваем tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
            "        72, 73, 74, 75, 76, 77, 78, 79])\n",
            "смежность False\n",
            "ошибка view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
            "решейпим tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
            "        36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70,\n",
            "        72, 74, 76, 78,  1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27,\n",
            "        29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63,\n",
            "        65, 67, 69, 71, 73, 75, 77, 79])\n",
            "делаем смежным и решейпим tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
            "        36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70,\n",
            "        72, 74, 76, 78,  1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27,\n",
            "        29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63,\n",
            "        65, 67, 69, 71, 73, 75, 77, 79])\n"
          ]
        }
      ],
      "source": [
        "# view vs reshape\n",
        "x = torch.arange(4*10*2).view(4, 10, 2)\n",
        "y = x.permute(2, 0, 1)\n",
        "\n",
        "# View - работает только на contiguous tensors (которые \"правильно\" последовательно лежат в памяти)\n",
        "print('смежность', x.is_contiguous())\n",
        "print('вытягиваем', x.view(-1))\n",
        "\n",
        "# Reshape - работает всегда (старается выдать view, если не получается делает копию данных)\n",
        "print('смежность', y.is_contiguous())\n",
        "try:\n",
        "    print('вытягиваем', y.view(-1))\n",
        "except RuntimeError as e:\n",
        "    print('ошибка', e)\n",
        "print('решейпим', y.reshape(-1))\n",
        "print('делаем смежным и решейпим', y.contiguous().view(-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb_GtKCssNhi"
      },
      "source": [
        "Для справки: в Pytorch-е тензоры хранятся в формате  [channel,\n",
        "height, width], в других системах чаще [height, width,\n",
        "channel]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3jmeXWbsNhj"
      },
      "source": [
        "### Тензоры: операции\n",
        "\n",
        "аналогичны операциям в numpy, большинство операций выполняются поэлементно.\n",
        "\n",
        "поддерживаются операции линейной алгебры, многие из которых взяты из библиотек Basic Linear Algebra Subprograms (BLAS) и Linear Algebra Package (LAPACK). Полный список операций линейной алгебры: https://pytorch.org/docs/stable/torch.html#blas-and-lapack-operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuy9n0JFsNhj"
      },
      "source": [
        "В inplace-операциях используется черта, в этом случае операция выполняется на данном тензоре:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CksxfbWasNhj",
        "outputId": "1d87b276-9719-4c2d-afd5-1a05b8f591e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[3, 3],\n",
            "        [3, 3]])\n",
            "tensor([[0, 0],\n",
            "        [0, 0]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "# заполнение\n",
        "x.fill_(3) # черта - признак выполнения на данном тензоре\n",
        "print (x)\n",
        "\n",
        "# обнуление\n",
        "x.zero_()\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRWEOCKosNhj"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = torch.tensor([[2, 2], [2, 2]])\n",
        "v = torch.tensor([1, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kuo4eAdwsNhk",
        "outputId": "edf29b88-da89-43ad-b916-e6ea452f9c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[5, 6],\n",
            "        [7, 8]]) tensor([[5, 6],\n",
            "        [7, 8]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[5, 6],\n",
              "        [7, 8]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# сложение\n",
        "print (x + y,\n",
        "       x.add(y))\n",
        "\n",
        "# черта означает inplace-операцию - меняется первый тензор:\n",
        "x.add_(y)\n",
        "\n",
        "# inplace-операции специально \"запрятаны\", так как при их использовании могут быть проблемы при распространении градиента"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezn9aZv5sNhk",
        "outputId": "00455a5c-1ccd-489c-ac20-cda421967411"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[2, 4],\n",
              "         [6, 8]]),\n",
              " tensor([[2, 4],\n",
              "         [6, 8]]),\n",
              " tensor([[2, 4],\n",
              "         [6, 8]]))"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = torch.tensor([[2, 2], [2, 2]])\n",
        "\n",
        "# поэлементное умножение\n",
        "x * y, x.mul(y), torch.mul(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lb6CzGYsNhk"
      },
      "source": [
        "Матричное умножение можно сделать по-разному:\n",
        "\n",
        "* torch.matmul - операция определена над тензорами, можно указывать размерность для умножения (см)\n",
        "* torch.mm - обычное матричное умножение, но без приведения размеров (broadcasting)\n",
        "* torch.bmm - матричное умножение с поддержкой батчей: $(b\\times n\\times m) \\cdot  (b\\times m\\times p) = b\\times n\\times p$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1Gog5uvsNhl",
        "outputId": "b3192a18-d011-4270-8983-a77e082e5f1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 6,  6],\n",
              "         [14, 14]]),\n",
              " tensor([[ 6,  6],\n",
              "         [14, 14]]),\n",
              " tensor([[ 6,  6],\n",
              "         [14, 14]]),\n",
              " tensor([[ 6,  6],\n",
              "         [14, 14]]))"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# матричное умножение\n",
        "x @ y, x.mm(y), x.matmul(y), torch.matmul(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnrDHggwsNhl",
        "outputId": "eedf74f6-4537-4a08-c963-92b7ad21a20f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1, 3],\n",
              "         [0, 1]]),\n",
              " tensor([[1, 3],\n",
              "         [0, 1]]))"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 1], [0, 1]])\n",
        "torch.linalg.multi_dot((x, x, x)), torch.matrix_power(x, 3) # перемножить несколько матриц / возвести в степень"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umPITBIjsNhl",
        "outputId": "05e5d3db-1a95-406c-9b34-69158d2c87be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 3],\n",
              "        [1, 2]])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 1], [0, 1]])\n",
        "y = torch.tensor([[1, 1], [1, 1]])\n",
        "torch.addmm(y, x, x) # y + x*x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbOzfi7ZsNhm",
        "outputId": "f3657fc2-2314-4094-d9ca-3c87961bc76a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5) tensor(5)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(20)"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = torch.tensor([[2, 2], [2, 2]])\n",
        "v = torch.tensor([1, 2])\n",
        "\n",
        "print (torch.dot(v, v), v.dot(v)) # скалярное умножение\n",
        "torch.dot(x.view(-1), y.view(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3EccLmlsNhn",
        "outputId": "e4773ab2-afce-46da-e9c6-cc8bbcba4cd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 5, 11]), tensor([ 5, 11]))"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mv(x, v), x.mv(v)  # умножение на вектор"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# специфика умножения\n",
        "\n",
        "import torch\n",
        "A = torch.rand(4,4)\n",
        "x = torch.rand(4)\n",
        "\n",
        "print (torch.mv(A, x)) # torch.mm(A, x) - ошибка\n",
        "print (torch.mm(A, x.view(4, 1))) # torch.mv(A, x.view(4, 1)) - ошибка"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyuvbw8GN8PZ",
        "outputId": "7c6e9e05-ba72-4b29-f980-30742528d6e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8222, 0.4081, 0.8190, 0.6435])\n",
            "tensor([[0.8222],\n",
            "        [0.4081],\n",
            "        [0.8190],\n",
            "        [0.6435]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkQgvXopsNhn",
        "outputId": "61dc6e96-4957-4b5f-8455-3102b1050e98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 6, 13])"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v.addmv(x, v) # vector + matrix @ vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeqvj36esNho",
        "outputId": "e828b5ad-dca4-4cc1-a411-7e4df08d8e34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[2., 2.],\n",
              "         [2., 5.]]),\n",
              " tensor(5))"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.eye(2)\n",
        "v = torch.tensor([1, 2])\n",
        "\n",
        "torch.addr(x, v, v), v.T @ v # matrix + vector * vector.T (внешнее произведение)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmrwJaqlsNho",
        "outputId": "7762392b-189b-41c4-8365-dbb725b051f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.return_types.eig(\n",
              " eigenvalues=tensor([[-0.3723,  0.0000],\n",
              "         [ 5.3723,  0.0000]]),\n",
              " eigenvectors=tensor([])),\n",
              " tensor(-2.0000),\n",
              " tensor(nan),\n",
              " tensor([[-2.0000,  1.0000],\n",
              "         [ 1.5000, -0.5000]]))"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1., 2.], [3., 4.]])\n",
        "\n",
        "torch.eig(x), torch.det(x), torch.logdet(x), torch.inverse(x)  # собственные значения, определители и обратная матрица"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRmVHpcVsNho",
        "outputId": "40a3dfc6-7bf6-47e2-d4fe-b974c61502d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0000],\n",
            "        [0.5000]]) tensor([[3.0000, 4.0000],\n",
            "        [0.3333, 0.6667]])\n",
            "tensor([[1.],\n",
            "        [2.]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-56-a17911f8d9bf>:4: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
            "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
            "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
            "X = torch.solve(B, A).solution\n",
            "should be replaced with\n",
            "X = torch.linalg.solve(A, B) (Triggered internally at  ..\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:760.)\n",
            "  a, lu = torch.solve(v, x) # решение матричного уравнения\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1., 2], [3, 4]])\n",
        "v = torch.tensor([[1., 2]]).T\n",
        "\n",
        "a, lu = torch.solve(v, x) # решение матричного уравнения\n",
        "print (a, lu)\n",
        "# проверка\n",
        "print (x @ a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHypFdLdsNhp",
        "outputId": "11859cf1-736f-4486-c82f-55a069b4dbaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.return_types.svd(\n",
              " U=tensor([[-0.4046, -0.9145],\n",
              "         [-0.9145,  0.4046]]),\n",
              " S=tensor([5.4650, 0.3660]),\n",
              " V=tensor([[-0.5760,  0.8174],\n",
              "         [-0.8174, -0.5760]])),\n",
              " (tensor([[ 0.7071,  0.7071],\n",
              "          [-0.7071,  0.7071]]),\n",
              "  tensor([2.0000e+00, 1.4426e-15]),\n",
              "  tensor([[-0.7071,  0.7071],\n",
              "          [-0.7071, -0.7071]])))"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.svd(x), torch.torch.pca_lowrank(x, niter=1) # SVD / PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRe-Fh7YsNhp",
        "outputId": "abfc406b-ed33-48d0-fe5c-1a3da76e9ab4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.div(x, y) # деление"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFl91kwPsNhp",
        "outputId": "d125b4cc-3f4d-4b18-d82c-21fc4731a96c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1., -2.],\n",
              "        [-3., -4.]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.neg(x) # унарный минус"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkrtOFFQsNhq",
        "outputId": "c34b61e5-ad4e-4914-b8b8-f7e71c9cad4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.5000],\n",
              "        [0.3333, 0.2500]])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.reciprocal(x) # 1/x поэлементно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q279o_69sNhq",
        "outputId": "d13352e0-5416-41af-9d48-d770a020e1d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.true_divide(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNXvgLfqsNhq",
        "outputId": "f3c92e08-b49e-4c63-d9b3-840f643c3c91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.6931],\n",
              "        [1.0986, 1.3863]], dtype=torch.float64)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.type(torch.DoubleTensor).log() # приводим тип - иначе не сработает log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XviuiGdYsNhr",
        "outputId": "ec0ca56b-4db6-4f01-98f9-d5270a33130b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 1.,  4.],\n",
              "         [ 9., 16.]]),\n",
              " tensor([[ 1.,  4.],\n",
              "         [ 9., 16.]]))"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.pow(2), x**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB5jiAW3sNhr",
        "outputId": "cbffb7df-24e2-4937-db07-f5b15f55ae72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 2.7183,  7.3891],\n",
              "         [20.0855, 54.5981]]),\n",
              " tensor([[0.0000, 0.6931],\n",
              "         [1.0986, 1.3863]]),\n",
              " tensor([[ 1.7183,  6.3891],\n",
              "         [19.0855, 53.5981]]),\n",
              " tensor([[0.6931, 1.0986],\n",
              "         [1.3863, 1.6094]]),\n",
              " tensor([[0.0000, 1.0000],\n",
              "         [1.5850, 2.0000]]))"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.exp(), x.log(), x.expm1(), x.log1p(), x.log2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsNe-ekZsNhr",
        "outputId": "0b035ee6-fef6-4436-cfb5-39ff96e1b695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[15,  9],\n",
            "        [12, 15]])\n",
            "tensor([[15,  3],\n",
            "        [ 8, 15]])\n",
            "tensor([[25,  9],\n",
            "        [16, 25]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[3, 1], [2, 3]])\n",
        "print(3 * x.add(2)) # смотри на порядок операций\n",
        "print(x * x.add(2)) # смотри на порядок операций\n",
        "print(x * x.add_(2)) # смотри на порядок операций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL71pTLhsNhs",
        "outputId": "6f9e84d5-8324-4dde-fd38-a2d3486fe926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2., 1.])\n",
            "tensor([2., 1.])\n",
            "tensor([2., 1.])\n",
            "tensor([2., 1.])\n"
          ]
        }
      ],
      "source": [
        "# как распределяется память - ПРОВЕРИТЬ В ПОСЛЕДНЕЙ ВЕРСИИ?????\n",
        "\n",
        "x = torch.Tensor([1, 2])\n",
        "y = torch.Tensor([1, 1])\n",
        "z = torch.Tensor([0, 2])\n",
        "\n",
        "print (x + y - z) # два промежуточных тензора будут созданы.\n",
        "print (x.add(y).sub_(z)) # один промежуточный тензор.\n",
        "print (x.add_(y).sub_(z)) # не будет создано промежуточных тензоров\n",
        "print(x) # поменяется"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCBSuqfZsNhs"
      },
      "source": [
        "### Тензоры: статистики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAeLTg85sNhs"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = torch.tensor([[2, 2], [2, 2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPT73SucsNht",
        "outputId": "faf7c616-b362-467c-f751-fb38c1527af8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(10), tensor(10), 10, tensor([4, 6]), tensor([3, 7]))"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# можно последовательно выполнять операции, например, сначала sum, потом item\n",
        "# item - \"выцепляет\" элемент\n",
        "torch.sum(x), x.sum(), x.sum().item(), x.sum(axis=0), x.sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WM4CHrS_sNht",
        "outputId": "2b648683-4cee-4052-9918-9dc653d9e627"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3],\n",
              "        [7]])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.sum(axis=1, keepdim=True) # keepdim - тензор остаётся двумерным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agaZl7tqsNhu",
        "outputId": "0384c483-1030-43f3-d6f6-a64481da1a37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(24), tensor(24))"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.prod(x), x.prod() # произведение элементов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCG4c_nksNhu",
        "outputId": "ff89591e-2385-408c-e84c-884a13de8ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(4),\n",
              " tensor(4),\n",
              " 4,\n",
              " torch.return_types.max(\n",
              " values=tensor([3, 4]),\n",
              " indices=tensor([1, 1])),\n",
              " torch.return_types.max(\n",
              " values=tensor([2, 4]),\n",
              " indices=tensor([1, 1])))"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.max(x), x.max(), x.max().item(), x.max(axis=0), x.max(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHaXYYJSsNhu",
        "outputId": "539c6c0a-d331-4481-e13b-1a3296d37893"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([3, 4]), tensor([1, 1]))"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "maxes, indexes = x.max(axis=0)\n",
        "maxes, indexes # одновременно получаем max и argmax - часто используется"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNpOfHlDsNhu",
        "outputId": "53c29054-530c-4077-c3c7-edc8c6391349"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(3), tensor([0, 0]))"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.argmax(), x.argmin(dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZzwxOvFsNhv",
        "outputId": "7d69d0c1-0271-4b33-c2b0-8d9fed165bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0598)\n",
            "tensor(5.4772)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1., 2.], [3., 4.]])\n",
        "y = torch.tensor([[2., 2.], [2., 2.]])\n",
        "\n",
        "print (torch.dist(x, y, p=4)) # p-норма\n",
        "print(x.norm())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjSHmGe3sNhw",
        "outputId": "4697973c-08fe-4d76-a5cb-129a3f611a04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(2.5000),\n",
              " tensor(2.),\n",
              " torch.return_types.mode(\n",
              " values=tensor([1., 3.]),\n",
              " indices=tensor([0, 0])))"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.mean(), x.median(), x.mode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0N4gf_TsNhw",
        "outputId": "3fc7c13b-9e5b-408c-bcb5-e7a6e66d7439"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [0, 1]])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.argsort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4sby4yrsNhw",
        "outputId": "33e8e237-8551-4aca-e606-c3bde710f91b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.return_types.topk(\n",
              " values=tensor([4, 3]),\n",
              " indices=tensor([5, 3])),\n",
              " torch.return_types.kthvalue(\n",
              " values=tensor(1),\n",
              " indices=tensor(1)))"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([2,1,2,3,0,4,3])\n",
        "x.topk(k=2), x.kthvalue(k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT_rfEFpsNhw",
        "outputId": "61e79a0c-b41a-4257-f2d3-8b48fff5f31e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((tensor(1.), tensor(2.)), (tensor(1.), tensor(2.)))"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1., 2., 3.])\n",
        "torch.std_mean(x), torch.var_mean(x) # сразу вычислить СКО / дисперсию и среденее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1fwIgyrsNhx",
        "outputId": "66f649ce-0bfd-4220-e036-7c7e4f778c1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.unique(torch.tensor([1,2,1,3,3,3,0])) # уникальные элементы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkGXU5_2sNhx",
        "outputId": "f799c585-37e3-48a6-f301-a085433b5303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[False,  True],\n",
              "         [False, False]]),\n",
              " tensor([[False,  True],\n",
              "         [False, False]]),\n",
              " tensor([[True, True],\n",
              "         [True, True]]),\n",
              " tensor([[True, True],\n",
              "         [True, True]]))"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = torch.tensor([[2, 2], [2, 2]])\n",
        "\n",
        "x == y, torch.eq(x, y), x == x, torch.eq(x, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6d9gmfMsNhx",
        "outputId": "b7bdf8a7-e114-466a-b6d3-87ea1b89fa70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.allclose(x, y) # равенство с некоторой точностью"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDegXONgsNhy",
        "outputId": "e557465b-c345-4845-e1f8-3ee810b3fc9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[False,  True],\n",
              "         [ True,  True]]),\n",
              " tensor([[False,  True],\n",
              "         [ True,  True]]),\n",
              " tensor([[False, False],\n",
              "         [ True,  True]]),\n",
              " tensor([[False, False],\n",
              "         [ True,  True]]),\n",
              " tensor([[ True,  True],\n",
              "         [False, False]]),\n",
              " tensor([[ True,  True],\n",
              "         [False, False]]),\n",
              " tensor([[ True, False],\n",
              "         [False, False]]),\n",
              " tensor([[ True, False],\n",
              "         [False, False]]))"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x >= y, torch.ge(x, y), x > y, torch.gt(x, y), x <= y, torch.le(x, y), x < y, torch.lt(x, y),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rJeflbesNh0",
        "outputId": "9f145d61-7856-4daf-a1ba-eb16fe0ba739"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1.0000,    inf],\n",
              "         [0.3333, 0.2500]]),\n",
              " tensor([[False,  True],\n",
              "         [False, False]]),\n",
              " tensor([[ True, False],\n",
              "         [ True,  True]]),\n",
              " tensor([[False, False],\n",
              "         [False, False]]))"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = 1 / torch.tensor([[1, 0], [3, 4]])\n",
        "x, torch.isinf(x), torch.isfinite(x), torch.isnan(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4EhXuXqsNh1"
      },
      "source": [
        "###  Тензоры: приведение размеров\n",
        "\n",
        "- когда 2 размерности совпадают\n",
        "- когда одна размерность равна 1\n",
        "\n",
        "не надо вручную приводить размеры \"размножая тензор\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm5DxV0usNh1",
        "outputId": "051530fc-499a-4627-a941-f4a95bb3fedd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[11, 22],\n",
              "        [13, 24]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# приведение размеров\n",
        "\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = torch.tensor([10, 20])\n",
        "\n",
        "x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzPjT70hsNh1",
        "outputId": "fc22197a-5191-451b-bfd2-98af60790499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2]]) torch.Size([1, 2])\n",
            "tensor([[0],\n",
            "        [3]]) torch.Size([2, 1])\n",
            "tensor([[1, 2],\n",
            "        [4, 5]]) torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "# приведение размеров\n",
        "\n",
        "x = torch.tensor([[1, 2]])\n",
        "y = torch.tensor([[0], [3]])\n",
        "print (x, x.shape)\n",
        "print (y, y.shape)\n",
        "z = x + y\n",
        "print (z, z.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NahCk8TIsNh2",
        "outputId": "b5f4dd58-13ae-4594-fa4d-7bc3c98171c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 0.0000e+00, 1.8754e+28],\n",
              "        [1.6244e-07, 2.1865e+23, 1.0471e-11]])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# приведение типов - а есть ещё x.type_as(y)\n",
        "\n",
        "x =  torch.FloatTensor(2, 3) + torch.IntTensor(2, 3)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pVzSymEsNh2",
        "outputId": "95090acd-3730-492b-e587-bad45c7085fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# приведение типов - а есть ещё x.type_as(y)\n",
        "\n",
        "torch.IntTensor(2, 3) + 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_y-vnAUsNh3"
      },
      "source": [
        "### Тензоры: связь с Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f8nEMgksNh3",
        "outputId": "0855386e-35de-40c6-f2e5-35b8af110a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ],
      "source": [
        "# Перевод тензора в numpy-массив осуществляется следующим образом\n",
        "\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "x.numpy()\n",
        "y = x.cpu().detach().numpy() # правильнее так\n",
        "print (y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0, 0] = 10\n",
        "print (y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfZilx-elCk3",
        "outputId": "fe7aeaa6-2df8-41e9-fb21-29c6d9c49dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10  2]\n",
            " [ 3  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRMEVykMsNh3",
        "outputId": "a63179f4-f0ae-4c11-ae31-12c8f7e85433"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 2], [3, 4]]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.tolist() # если хотим просто в список"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCcistVvsNh4",
        "outputId": "5c988f96-ac9f-431b-9a00-02fb79f1f360"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# из numpy.array в pytorch-тензор\n",
        "torch.from_numpy(np.ones((2, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xItGaZ2PsNh4",
        "outputId": "5b10395c-e841-47f8-b20f-2658ecba77de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "[11. 11. 11. 11. 11.]\n",
            "tensor([11., 11., 11., 11., 11.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "# Посмотрим, как изменения массива в numpy атоматичесменяет тензор\n",
        "\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "c = torch.Tensor(a)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "np.add(a, 10, out=a)\n",
        "# если использовать конструкцию a = a + 1, то изменения тензора не произойдёт\n",
        "print(a)\n",
        "print(b)\n",
        "print(c) # а тут нет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPj2J7WPsNh4",
        "outputId": "aaa5ebb6-2133-4c97-9e09-ee22a48a6093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 2]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-95-8f8f3d4bc075>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# будет ошибка\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "# При переводе в numpy необходимо, чтобы тензор находился в CPU, а не на GPU.\n",
        "\n",
        "x = torch.tensor([1, 2], device='cuda')\n",
        "print (x.cpu().numpy())\n",
        "print (x.numpy()) # будет ошибка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWcAKV1HsNh5"
      },
      "source": [
        "### Тензоры: сохранение и загрузка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6j82LBBsNh5",
        "outputId": "30082d05-b426-4d32-c926-5215648698a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# сохранение и загрузка тензоров\n",
        "torch.save(x, 'x-file')\n",
        "x2 = torch.load(\"x-file\")\n",
        "x2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8D2s3JqtsNh5",
        "outputId": "71697f58-b90f-4784-fcbc-96872d693c9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3.]),\n",
              " tensor([[ 3.,  0.],\n",
              "         [ 3., 12.]], requires_grad=True))"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.save([x, y], 'x-files')\n",
        "x2, y2 = torch.load('x-files')\n",
        "(x2, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_S9cXBdsNh5",
        "outputId": "33393d05-c6c1-4ddf-b1a5-c6ba63ed5975"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'x': tensor([1., 2., 3.]),\n",
              " 'y': tensor([[ 3.,  0.],\n",
              "         [ 3., 12.]], requires_grad=True)}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydict = {'x': x, 'y': y}\n",
        "torch.save(mydict, 'mydict')\n",
        "mydict2 = torch.load('mydict')\n",
        "mydict2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoRzRzNusNh6"
      },
      "source": [
        "## Тензоры: примеры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNqO1REwsNh6",
        "outputId": "0b71439a-baf7-4802-997a-4d1101fbdb76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# OHE\n",
        "target = torch.tensor([0,3,2,2,0])\n",
        "target_onehot = torch.zeros(target.shape[0], 10)\n",
        "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z-hxw5PsNh6",
        "outputId": "4894cfca-e126-4947-cdc3-4f455675997b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 20, 1200])\n",
            "torch.Size([10, 20, 1200])\n"
          ]
        }
      ],
      "source": [
        "# матрица -> вектор\n",
        "x = torch.rand(10, 20, 30, 40)\n",
        "print (x.view(-1, 20, 30*40).shape)\n",
        "print (torch.flatten(x, 2).shape) # после какой размерности вытягивать (это аналог reshape!)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# нормировка\n",
        "\n",
        "a_norm = a / a.norm(dim=1)[:, None]"
      ],
      "metadata": {
        "id": "u8W5yTpLMD-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcflxRjWsNh7"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Тензоры и вычислительные графы (нейросети) могут находиться как на CPU, так и на GPU (ещё на TPU). Переменные и модели на разных устройствах не видят друг друга! Поэтому их надо перенести на один вычислитель.\n",
        "\n",
        "На GPU вычисления производятся существенно быстрее из-за параллелизма.\n",
        "\n",
        "Такие записи эквивалентны для обозначения устройства-GPU:\n",
        "\n",
        "- device=\"cuda\"\n",
        "- device=torch.device(\"cuda\")\n",
        "- device=\"cuda:0\"\n",
        "- device=torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANWmo66RsNh7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# самая популярная конструкция, определяющая доступное для хранения тензоров/нейросетей устройство\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перенос тензора / нейросети на устройство осуществляется с помощью инструкции ```to```."
      ],
      "metadata": {
        "id": "EkRShpZVuB5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m.to(device) # перенос на доступное устройство"
      ],
      "metadata": {
        "id": "VOMFgoCJuaoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# информация о GPU\n",
        "\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMQWzNS1tC3y",
        "outputId": "2238898e-ae22-451c-8414-269957c3932c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "\n",
            "Tesla T4\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# чистка памяти\n",
        "\n",
        "gc.collect() # Python thing\n",
        "\n",
        "with torch.no_grad(): # работает с этой инструкцией\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "e4UgepjJu0cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cthqnM8ysNh8",
        "outputId": "b970bb62-af26-42ec-b49a-844a95d43232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU time: 0.77800s\n",
            "CPU2GPU time: 0.09263s\n",
            "GPU time: 0.00803s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "# CPU\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "# GPU\n",
        "start_time = time.time()\n",
        "x = x.to(\"cuda:0\")\n",
        "end_time = time.time()\n",
        "print(f\"CPU2GPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "x = x + 0.0 # просто первая операция\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"GPU time: {(end_time - start_time):6.5f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWfxZjPksNh8"
      },
      "outputs": [],
      "source": [
        "# инициализация генератора псевдослучайных чисел\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): # для GPU отдельный seed\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# есть стохастические операции на GPU\n",
        "# сделаем их детерминированными для воспроизводимости\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi4EwnSwsNh9"
      },
      "outputs": [],
      "source": [
        "x.cuda()\n",
        "x.cpu()\n",
        "x.is_cuda\n",
        "z.to(\"cpu\", torch.double)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQR0j6qjsNh9"
      },
      "source": [
        "Ниже эксперименты со временем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N29BM0RmsNh9"
      },
      "outputs": [],
      "source": [
        "x = torch.randn((1000, 1000))\n",
        "y = torch.randn((1000, 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoemOqFysNh-",
        "outputId": "01cbc75d-d261-4e17-c88b-f6a6c17778dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 11 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "z = x @ y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjADs1RWsNh-",
        "outputId": "022aa076-a0b0-49b3-bbdc-4387e94b3767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 4.96 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "x = x.cuda()\n",
        "y = y.cuda() # на перебрасывание тоже нужно время\n",
        "z = x @ y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwBQe7xTsNh-",
        "outputId": "03de5f98-0242-434c-e922-f5cac774c873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "используется сейчас:: 201.0MB \n"
          ]
        }
      ],
      "source": [
        "# сколько используется памяти\n",
        "def print_peak_memory(prefix, device):\n",
        "    print(f\"{prefix}: {torch.cuda.max_memory_allocated(device) // 1e6}MB \")\n",
        "\n",
        "device=\"cuda\"\n",
        "print_peak_memory(\"используется сейчас:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6iBg3losNh_"
      },
      "source": [
        "## Авто дифференцирование (AutoGrad)\n",
        "\n",
        "Сначала приведём пример автоматического дифференцирования, мы зададим функцию $y = sin(x) \\cdot (sin^2(x) + cos^2(x)$, а Pytorch автоматически вычислит её производную.\n",
        "\n",
        "backward - функция \"обратного прохода\", именно при её вызове автоматически считаются производные по всем переменным, у которых requires_grad=True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YINtf9DosNh_",
        "outputId": "d1ea4987-694a-4f26-eae6-76aeacf24292"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x26d45e519a0>"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "x = torch.linspace(-2, 2, 101, dtype=torch.float32, requires_grad=True)\n",
        "# x = Variable(x, requires_grad=True) # можно ли проще? - да!\n",
        "y = torch.sin(x) * (torch.sin(x) ** 2 + torch.cos(x) **2)\n",
        "# здесь это прямой проход\n",
        "# дальще часто будем определять класс с методом y.forward()\n",
        "y.sum().backward() # превращаем в число (только от таких фукнций берётся градиент)\n",
        "g = x.grad # взятие производных в каждой точке\n",
        "\n",
        "plt.plot(x.detach().numpy(), y.detach().numpy(), c='#000099', label='$y$')\n",
        "plt.plot(x.detach().numpy(), g.detach().numpy(), c='#FFAAAA', label=\"$y'$\")\n",
        "plt.xlabel('$x$')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSZ5NiIgsNh_",
        "outputId": "0b529d1c-d620-4f1a-afc1-cd1d58dd3c49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-2.,  0.,  2.], requires_grad=True)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.linspace(-2, 2, 3, dtype=torch.float32) # над целочисленными тензорами нельзя взять производную\n",
        "x.requires_grad_() # как указать, что хотим вычислять производную\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQTOMsJJsNiA",
        "outputId": "5affdbee-f4c4-44d3-d608-83676894956e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([-1.]), tensor([2.]), tensor([-3.]))"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "#x = Variable(torch.Tensor([1]), requires_grad=True)\n",
        "#y = Variable(torch.Tensor([2]), requires_grad=True)\n",
        "#z = Variable(torch.Tensor([3]), requires_grad=True)\n",
        "\n",
        "x = torch.tensor([1.], requires_grad=True)\n",
        "y = torch.tensor([2.], requires_grad=True)\n",
        "z = torch.tensor([3.], requires_grad=True)\n",
        "\n",
        "f = (x + y) * (y - z)\n",
        "\n",
        "f.backward()\n",
        "x.grad, y.grad, z.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuJU0XZgsNiA",
        "outputId": "47bf7b2b-c0c2-4712-8acb-b2b77db54a3b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchviz'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-111-76da507f43cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchviz\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmake_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchviz'"
          ]
        }
      ],
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "make_dot(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4CIF3iasNiA",
        "outputId": "cec8713d-15ea-4c88-8b96-c283078e3111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "f = (x + y) * (y - z)\n",
        "z = f.detach()\n",
        "print (f.requires_grad, z.requires_grad)\n",
        "\n",
        "with torch.no_grad(): # когда просто нужен прямой проход - и не надо считать градиенты\n",
        "    f = (x + y) * (y - z)\n",
        "print (f.requires_grad)\n",
        "\n",
        "# если устраняем вычисления градиентов - считается быстрее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_AO1E0OsNiB",
        "outputId": "3f682ec8-112d-42b0-beee-c422acb35ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.5000, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "y = 3 * (x - 2) ** 2\n",
        "\n",
        "f = y.mean()\n",
        "\n",
        "print (f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NQgrj8FsNiC",
        "outputId": "4143382f-42fa-433a-d394-af7d4d397ec6"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
              "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
              " -->\r\n",
              "<!-- Title: %3 Pages: 1 -->\r\n",
              "<svg width=\"104pt\" height=\"271pt\"\r\n",
              " viewBox=\"0.00 0.00 104.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\r\n",
              "<title>%3</title>\r\n",
              "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-267 100,-267 100,4 -4,4\"/>\r\n",
              "<!-- 1686543498824 -->\r\n",
              "<g id=\"node1\" class=\"node\"><title>1686543498824</title>\r\n",
              "<polygon fill=\"#caff70\" stroke=\"black\" points=\"96,-21 0,-21 0,-0 96,-0 96,-21\"/>\r\n",
              "<text text-anchor=\"middle\" x=\"48\" y=\"-7.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MeanBackward0</text>\r\n",
              "</g>\r\n",
              "<!-- 1686543497144 -->\r\n",
              "<g id=\"node2\" class=\"node\"><title>1686543497144</title>\r\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"92,-78 4,-78 4,-57 92,-57 92,-78\"/>\r\n",
              "<text text-anchor=\"middle\" x=\"48\" y=\"-64.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MulBackward0</text>\r\n",
              "</g>\r\n",
              "<!-- 1686543497144&#45;&gt;1686543498824 -->\r\n",
              "<g id=\"edge1\" class=\"edge\"><title>1686543497144&#45;&gt;1686543498824</title>\r\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M48,-56.9197C48,-49.9083 48,-40.1442 48,-31.4652\"/>\r\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"51.5001,-31.3408 48,-21.3408 44.5001,-31.3409 51.5001,-31.3408\"/>\r\n",
              "</g>\r\n",
              "<!-- 1686543496136 -->\r\n",
              "<g id=\"node3\" class=\"node\"><title>1686543496136</title>\r\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"93.5,-135 2.5,-135 2.5,-114 93.5,-114 93.5,-135\"/>\r\n",
              "<text text-anchor=\"middle\" x=\"48\" y=\"-121.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">PowBackward0</text>\r\n",
              "</g>\r\n",
              "<!-- 1686543496136&#45;&gt;1686543497144 -->\r\n",
              "<g id=\"edge2\" class=\"edge\"><title>1686543496136&#45;&gt;1686543497144</title>\r\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M48,-113.92C48,-106.908 48,-97.1442 48,-88.4652\"/>\r\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"51.5001,-88.3408 48,-78.3408 44.5001,-88.3409 51.5001,-88.3408\"/>\r\n",
              "</g>\r\n",
              "<!-- 1686401450672 -->\r\n",
              "<g id=\"node4\" class=\"node\"><title>1686401450672</title>\r\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"92,-192 4,-192 4,-171 92,-171 92,-192\"/>\r\n",
              "<text text-anchor=\"middle\" x=\"48\" y=\"-178.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SubBackward0</text>\r\n",
              "</g>\r\n",
              "<!-- 1686401450672&#45;&gt;1686543496136 -->\r\n",
              "<g id=\"edge3\" class=\"edge\"><title>1686401450672&#45;&gt;1686543496136</title>\r\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M48,-170.92C48,-163.908 48,-154.144 48,-145.465\"/>\r\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"51.5001,-145.341 48,-135.341 44.5001,-145.341 51.5001,-145.341\"/>\r\n",
              "</g>\r\n",
              "<!-- 1686543516616 -->\r\n",
              "<g id=\"node5\" class=\"node\"><title>1686543516616</title>\r\n",
              "<polygon fill=\"lightblue\" stroke=\"black\" points=\"75,-263 21,-263 21,-228 75,-228 75,-263\"/>\r\n",
              "<text text-anchor=\"middle\" x=\"48\" y=\"-235.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (2, 2)</text>\r\n",
              "</g>\r\n",
              "<!-- 1686543516616&#45;&gt;1686401450672 -->\r\n",
              "<g id=\"edge4\" class=\"edge\"><title>1686543516616&#45;&gt;1686401450672</title>\r\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M48,-227.885C48,-219.994 48,-210.505 48,-202.248\"/>\r\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"51.5001,-202.018 48,-192.018 44.5001,-202.018 51.5001,-202.018\"/>\r\n",
              "</g>\r\n",
              "</g>\r\n",
              "</svg>\r\n"
            ],
            "text/plain": [
              "<graphviz.dot.Digraph at 0x188add37898>"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "make_dot(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ooc5UVaEsNiC",
        "outputId": "17dd8909-4c69-4f9e-f3bc-ff3f16c7e299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]], requires_grad=True) tensor([[-1.5000,  0.0000],\n",
            "        [ 1.5000,  3.0000]]) tensor([[-1.5000,  0.0000],\n",
            "        [ 1.5000,  3.0000]], grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "f.backward()\n",
        "print(x, x.grad, 3*2*(x - 2)/4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x6549EusNiC",
        "outputId": "2b417866-a756-4904-b418-7e8f10fe6e02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x += 1 # будет ошибка - inplace-операции не работают\n",
        "f.grad, y.grad # тут тоже ничего нет !!! (не было requires_grad=True - по этим переменным не бралась производная)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQIi6AidsNiC",
        "outputId": "e66fc0e7-7bde-491d-9386-01cb156830fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "tensor([1., 2., 3.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([1, 2, 3])\n",
        "w = torch.tensor([1., 1, 1], requires_grad=True)\n",
        "z = w @ x\n",
        "z.backward()\n",
        "print(x.grad, # по этому не указывали возможность взятия градиента\n",
        "      w.grad, #  должен выводиться x\n",
        "      sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kelu9XGsNiC",
        "outputId": "e093695f-088c-44c7-b632-8b98666fafd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "tensor([2., 4., 6.])\n"
          ]
        }
      ],
      "source": [
        "z = w @ x\n",
        "z.backward()\n",
        "print(x.grad,\n",
        "      w.grad, # идёт накопление!!!\n",
        "      sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwMQ7myRsNiC",
        "outputId": "0b4877ff-accc-4856-bd7c-90ec49987459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "tensor([2., 4., 6.])\n",
            "None\n",
            "tensor([1., 2., 3.])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad(): # нет накопления\n",
        "    z = w @ x\n",
        "    # z.backward()\n",
        "print(x.grad, w.grad, sep='\\n')\n",
        "\n",
        "w.grad.data.zero_() # а так - совсем обнулить\n",
        "z = w @ x\n",
        "z.backward()\n",
        "print(x.grad, w.grad, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1pKyaPhsNiC",
        "outputId": "b8176d46-0fa8-4c96-b79f-8f808cf33457"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1.], dtype=float32)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# w.numpy() - будет ошибка\n",
        "w.detach().numpy() # создаётся копия, которую можно в np - у неё requires_grad=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILUbG8X5sNiD",
        "outputId": "44b30783-1ad7-4c2a-88a5-7b351c08f9a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([12.])\n"
          ]
        }
      ],
      "source": [
        "# Иллюстрация взятия градиента - без detach\n",
        "\n",
        "# from torch.autograd import Variable\n",
        "# x = Variable(torch.Tensor([2]), requires_grad=True)\n",
        "x = torch.tensor([2.], requires_grad=True)\n",
        "\n",
        "y = x * x\n",
        "z = x * y\n",
        "\n",
        "z.backward()\n",
        "\n",
        "print(x.grad) # (x^3)' = 3x^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_vOHD3ksNiE",
        "outputId": "10514e17-73c9-400d-e4bb-7bc7719cf2ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4.])\n"
          ]
        }
      ],
      "source": [
        "# Иллюстрация взятия градиента - теперь с detach\n",
        "\n",
        "# from torch.autograd import Variable\n",
        "# x = Variable(torch.Tensor([2]), requires_grad=True)\n",
        "x = torch.tensor([2.], requires_grad=True)\n",
        "\n",
        "y = x * x\n",
        "y.detach_() # добавили\n",
        "z = x * y\n",
        "# а тут не сработает\n",
        "z.backward()\n",
        "\n",
        "print(x.grad) # (2*2*x)' = 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ещё одна иллюстрация detach()\n",
        "import torch\n",
        "x = torch.tensor([2.], requires_grad=True)\n",
        "print(x)\n",
        "print(x.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXZcrJBv8uIl",
        "outputId": "67a5338f-43da-44ee-a79a-fa871808318c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.], requires_grad=True)\n",
            "tensor([2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ещё иллюстрация detach()  с визуализацией\n",
        "!pip install torchviz\n",
        "import torch\n",
        "from torchviz import make_dot\n",
        "x=torch.ones(2, requires_grad=True)\n",
        "y=2 * x\n",
        "z=3 + x\n",
        "r=(y + z).sum()\n",
        "make_dot(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "rI_M6WjXfk-t",
        "outputId": "01d1e9c9-9e03-4bce-b193-ea6401a8324b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1+cu118)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=91fb50e1e447dbee75ad5783ba260c5e2f457238b8a943a4fdf5e8220e795bef\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"204pt\" height=\"326pt\"\n viewBox=\"0.00 0.00 204.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-322 200,-322 200,4 -4,4\"/>\n<!-- 140569584050768 -->\n<g id=\"node1\" class=\"node\">\n<title>140569584050768</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"124.5,-31 70.5,-31 70.5,0 124.5,0 124.5,-31\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140572916182000 -->\n<g id=\"node2\" class=\"node\">\n<title>140572916182000</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"142,-86 53,-86 53,-67 142,-67 142,-86\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n</g>\n<!-- 140572916182000&#45;&gt;140569584050768 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140572916182000&#45;&gt;140569584050768</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97.5,-66.79C97.5,-60.07 97.5,-50.4 97.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"101,-41.19 97.5,-31.19 94,-41.19 101,-41.19\"/>\n</g>\n<!-- 140572916181520 -->\n<g id=\"node3\" class=\"node\">\n<title>140572916181520</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"142,-141 53,-141 53,-122 142,-122 142,-141\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140572916181520&#45;&gt;140572916182000 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140572916181520&#45;&gt;140572916182000</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97.5,-121.75C97.5,-114.8 97.5,-104.85 97.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"101,-96.09 97.5,-86.09 94,-96.09 101,-96.09\"/>\n</g>\n<!-- 140572916181664 -->\n<g id=\"node4\" class=\"node\">\n<title>140572916181664</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"89,-196 0,-196 0,-177 89,-177 89,-196\"/>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140572916181664&#45;&gt;140572916181520 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140572916181664&#45;&gt;140572916181520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M53.25,-176.75C60.97,-169.03 72.4,-157.6 81.72,-148.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"84.31,-150.64 88.91,-141.09 79.36,-145.69 84.31,-150.64\"/>\n</g>\n<!-- 140572916181424 -->\n<g id=\"node5\" class=\"node\">\n<title>140572916181424</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-251 47,-251 47,-232 148,-232 148,-251\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140572916181424&#45;&gt;140572916181664 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140572916181424&#45;&gt;140572916181664</title>\n<path fill=\"none\" stroke=\"black\" d=\"M88.75,-231.75C81.03,-224.03 69.6,-212.6 60.28,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"62.64,-200.69 53.09,-196.09 57.69,-205.64 62.64,-200.69\"/>\n</g>\n<!-- 140572916181472 -->\n<g id=\"node7\" class=\"node\">\n<title>140572916181472</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-196 107,-196 107,-177 196,-177 196,-196\"/>\n<text text-anchor=\"middle\" x=\"151.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140572916181424&#45;&gt;140572916181472 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140572916181424&#45;&gt;140572916181472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.42,-231.75C114.28,-224.03 125.93,-212.6 135.42,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"138.06,-205.59 142.75,-196.09 133.16,-200.6 138.06,-205.59\"/>\n</g>\n<!-- 140573279511200 -->\n<g id=\"node6\" class=\"node\">\n<title>140573279511200</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"124.5,-318 70.5,-318 70.5,-287 124.5,-287 124.5,-318\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n</g>\n<!-- 140573279511200&#45;&gt;140572916181424 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140573279511200&#45;&gt;140572916181424</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97.5,-286.92C97.5,-279.22 97.5,-269.69 97.5,-261.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"101,-261.25 97.5,-251.25 94,-261.25 101,-261.25\"/>\n</g>\n<!-- 140572916181472&#45;&gt;140572916181520 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140572916181472&#45;&gt;140572916181520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M142.58,-176.75C134.72,-169.03 123.07,-157.6 113.58,-148.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.84,-145.6 106.25,-141.09 110.94,-150.59 115.84,-145.6\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7fd9aebbeb30>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "x=torch.ones(2, requires_grad=True)\n",
        "y=2 * x\n",
        "z=3 + x.detach()\n",
        "r=(y + z).sum()\n",
        "make_dot(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "_j_nOHxUfsPb",
        "outputId": "449c083b-437d-4ad7-ff0e-96accbcea967"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"326pt\"\n viewBox=\"0.00 0.00 109.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-322 105,-322 105,4 -4,4\"/>\n<!-- 140572916254016 -->\n<g id=\"node1\" class=\"node\">\n<title>140572916254016</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140572916181568 -->\n<g id=\"node2\" class=\"node\">\n<title>140572916181568</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n</g>\n<!-- 140572916181568&#45;&gt;140572916254016 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140572916181568&#45;&gt;140572916254016</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 140572916180656 -->\n<g id=\"node3\" class=\"node\">\n<title>140572916180656</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140572916180656&#45;&gt;140572916181568 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140572916180656&#45;&gt;140572916181568</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 140572916180608 -->\n<g id=\"node4\" class=\"node\">\n<title>140572916180608</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-196 6,-196 6,-177 95,-177 95,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140572916180608&#45;&gt;140572916180656 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140572916180608&#45;&gt;140572916180656</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n</g>\n<!-- 140572916181184 -->\n<g id=\"node5\" class=\"node\">\n<title>140572916181184</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140572916181184&#45;&gt;140572916180608 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140572916181184&#45;&gt;140572916180608</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.75C50.5,-224.8 50.5,-214.85 50.5,-206.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.09 50.5,-196.09 47,-206.09 54,-206.09\"/>\n</g>\n<!-- 140569599352384 -->\n<g id=\"node6\" class=\"node\">\n<title>140569599352384</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-318 23.5,-318 23.5,-287 77.5,-287 77.5,-318\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n</g>\n<!-- 140569599352384&#45;&gt;140572916181184 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140569599352384&#45;&gt;140572916181184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.92C50.5,-279.22 50.5,-269.69 50.5,-261.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.25 50.5,-251.25 47,-261.25 54,-261.25\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7fd9aebbe5c0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# листья графа\n",
        "\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(4.0)\n",
        "c = a + b # => tensor(6., grad_fn=<AddBackward0>)\n",
        "\n",
        "a.requires_grad # => True\n",
        "a.is_leaf # => True\n",
        "\n",
        "b.requires_grad # => False\n",
        "b.is_leaf # => True\n",
        "\n",
        "c.requires_grad # => True\n",
        "c.is_leaf # => False"
      ],
      "metadata": {
        "id": "Dew8n6wGMrE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNRqYZ4KsNiE",
        "outputId": "8fdd7994-c9aa-4fa2-f9ca-36718f25dd79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  1.,  16.],\n",
            "        [ 81., 256.]], grad_fn=<MulBackward0>) \n",
            " None\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], requires_grad=True) \n",
            " tensor([[ 1.,  8.],\n",
            "        [27., 64.]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-123-7397ba33abd6>:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
            "  print(x, '\\n', x.grad)\n"
          ]
        }
      ],
      "source": [
        "# динамический граф вычислений в цикле\n",
        "\n",
        "x = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
        "x0 = x\n",
        "for _ in range(2):\n",
        "    x = x * x\n",
        "\n",
        "z = x.mean() # здесь будет 1/4 !!!\n",
        "z.backward()\n",
        "\n",
        "print(x, '\\n', x.grad)\n",
        "print(x0, '\\n', x0.grad) # градиент лежит здесь!!!\n",
        "# поскольку x превратился во внутреннюю вершину графа вычислений"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возможность вычислять отдельные производные.\n",
        "\n",
        "см. также https://stackoverflow.com/questions/43451125/pytorch-what-are-the-gradient-arguments"
      ],
      "metadata": {
        "id": "pct7txwBmytt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.autograd import Variable\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([[1., 2, 3, 4]], requires_grad=True)\n",
        "# x = Variable(torch.FloatTensor([[1, 2, 3, 4]]), requires_grad=True)\n",
        "z = x ** 2 / 2\n",
        "loss = z.sum(dim=1)\n",
        "\n",
        "# backward для первого элемента z\n",
        "z.backward(torch.FloatTensor([[1, 0, 0, 0]]), retain_graph=True)\n",
        "print(x.grad.data)\n",
        "x.grad.data.zero_() # grad <-0 для верности вывода\n",
        "\n",
        "# backward для второго элемента z\n",
        "z.backward(torch.FloatTensor([[0, 1, 0, 0]]), retain_graph=True)\n",
        "print(x.grad.data)\n",
        "x.grad.data.zero_()\n",
        "\n",
        "# backward для всех элементов z с равными весами\n",
        "z.backward(torch.FloatTensor([[1, 1, 1, 1]]), retain_graph=True)\n",
        "print(x.grad.data)\n",
        "x.grad.data.zero_()\n",
        "\n",
        "# обычный backward для loss\n",
        "loss.backward() # ~ loss.backward(torch.FloatTensor([1.0]))\n",
        "print(x.grad.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWYW6IaHmJHn",
        "outputId": "b934c687-335b-4c0e-caed-68caf85c9d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0.]])\n",
            "tensor([[0., 2., 0., 0.]])\n",
            "tensor([[1., 2., 3., 4.]])\n",
            "tensor([[1., 2., 3., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# два обратных прохода по графу\n",
        "\n",
        "import torch\n",
        "#from torch.autograd import Variable\n",
        "#a = Variable(torch.rand(1, 4), requires_grad=True)\n",
        "a = torch.rand(1, 4, requires_grad=True)\n",
        "b = a**2\n",
        "c = b*2\n",
        "d = c.mean()\n",
        "e = c.sum()\n",
        "\n",
        "# если так\n",
        "d.backward() #\n",
        "e.backward() # тут будет ошибка\n",
        "# RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n",
        "\n",
        "# надо так\n",
        "d.backward(retain_graph=True) #\n",
        "e.backward(retain_graph=True) #"
      ],
      "metadata": {
        "id": "3CKBDzR--4lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A09TZzgsNiE"
      },
      "source": [
        "Есть возможность вычисления Jacobian Product $v^TJ$\n",
        "**- про это пока не говорим**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Bd_ekasNiE"
      },
      "source": [
        "## Простой пример обучения - пока без НС"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Frlsi4PhsNiF",
        "outputId": "5b77658d-1b81-461a-be54-82c1fa0dc78c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-118-1e984e1a3eab>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  w = torch.tensor(torch.randn([3, 1]), requires_grad=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.9999995e+00]\n",
            " [1.0000000e+00]\n",
            " [1.5245234e-07]]\n"
          ]
        }
      ],
      "source": [
        "# полиномиальная регрессия\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "w = torch.tensor(torch.randn([3, 1]), requires_grad=True)\n",
        "\n",
        "opt = torch.optim.Adam([w], 0.1)\n",
        "\n",
        "def model(x):\n",
        "    # полином\n",
        "    f = torch.stack([x * x, x, torch.ones_like(x)], 1)\n",
        "    yhat = torch.squeeze(f @ w, 1)\n",
        "    return yhat\n",
        "\n",
        "#def compute_loss(y, yhat):\n",
        "#    # ошибка\n",
        "#    loss = torch.nn.functional.mse_loss(yhat, y)\n",
        "#    return loss\n",
        "\n",
        "# а можно так\n",
        "compute_loss = torch.nn.MSELoss()\n",
        "\n",
        "def generate_data():\n",
        "    # данные\n",
        "    x = torch.rand(100) * 2 - 1.0\n",
        "    y = 2 * x * x + x + 0.\n",
        "    return x, y\n",
        "\n",
        "def train_step():\n",
        "    x, y = generate_data()\n",
        "\n",
        "    yhat = model(x)\n",
        "    loss = compute_loss(y, yhat)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "for _ in range(1000):\n",
        "    train_step()\n",
        "\n",
        "print(w.detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rABPuA7YsNiF"
      },
      "outputs": [],
      "source": [
        "# а теперь в стиле нейросети\n",
        "import torch\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.a = torch.nn.Parameter(torch.rand(1))\n",
        "        self.b = torch.nn.Parameter(torch.rand(1))\n",
        "        self.c = torch.nn.Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        yhat = self.a * x * x + self.b * x + self.c\n",
        "        return yhat\n",
        "\n",
        "net = Net()\n",
        "# y = net(x)\n",
        "\n",
        "def train_step(model):\n",
        "    x, y = generate_data()\n",
        "\n",
        "    yhat = model(x)\n",
        "    loss = compute_loss(y, yhat)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    # print (loss.item())\n",
        "\n",
        "opt = torch.optim.Adam(net.parameters(), 0.1)\n",
        "\n",
        "for _ in range(1000):\n",
        "    train_step(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbNnZ2cxsNiF",
        "outputId": "14579111-33de-4023-e5d1-035c9c268722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([2.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.1171e-12], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for p in net.parameters():\n",
        "    print(p)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}